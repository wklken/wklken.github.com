<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>wklken's blog - system</title><link href="http://www.wklken.me/" rel="alternate"></link><link href="http://www.wklken.me/feeds/system.atom.xml" rel="self"></link><id>http://www.wklken.me/</id><updated>2016-06-29T00:00:00+08:00</updated><entry><title>ElasticSearch集群部署文档</title><link href="http://www.wklken.me/posts/2016/06/29/deploy-es.html" rel="alternate"></link><published>2016-06-29T00:00:00+08:00</published><updated>2016-06-29T00:00:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2016-06-29:/posts/2016/06/29/deploy-es.html</id><summary type="html">&lt;p&gt;官方es搭建步骤写的很简略, 但是实际搭建过程中, 会涉及一系列环境配置. 以下的流程, 是在搭建过程中梳理出来的详细步骤(实践过3遍以上)&lt;/p&gt;
&lt;p&gt;其实, 这些流程在具体应用的时候, 都可以变成自动化脚本, 或者直接用docker好了, 以便扩容足够快(目前我们用的打包成集成安装包, 实现脚本自动部署)&lt;/p&gt;
&lt;p&gt;只是简单集群的基本设置, 不涉及调优的参数配置, 不涉及&lt;code&gt;client/master/data&lt;/code&gt;节点区分等等. 可以参照搭建的主体流程.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="ban-ben-ji-lian-jie"&gt;版本及连接&lt;/h2&gt;
&lt;p&gt;elasticseearch版本: 2.3.3&lt;/p&gt;
&lt;p&gt;相关链接:
- &lt;a href="https://www.elastic.co/products/elasticsearch"&gt;官网&lt;/a&gt;
- &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="xi-tong-yao-qiu"&gt;系统要求&lt;/h2&gt;
&lt;p&gt;如果仅作测试用, 不需要两天机器, 可以将两个节点部署在同一台机器上, 对磁盘/cpu要求不高, 内存大于2g基本足够了&lt;/p&gt;
&lt;p&gt;如果是正式环境, 需要根据日志量进行评估, 例如, 每天日志量占硬盘约约10G, 且保留30天日志, 则磁盘会占用约300g, es设定的阈值是磁盘空间占满85%则日志开始告警. 所以, 需要至少 &lt;code&gt;300/0.85=354g …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;官方es搭建步骤写的很简略, 但是实际搭建过程中, 会涉及一系列环境配置. 以下的流程, 是在搭建过程中梳理出来的详细步骤(实践过3遍以上)&lt;/p&gt;
&lt;p&gt;其实, 这些流程在具体应用的时候, 都可以变成自动化脚本, 或者直接用docker好了, 以便扩容足够快(目前我们用的打包成集成安装包, 实现脚本自动部署)&lt;/p&gt;
&lt;p&gt;只是简单集群的基本设置, 不涉及调优的参数配置, 不涉及&lt;code&gt;client/master/data&lt;/code&gt;节点区分等等. 可以参照搭建的主体流程.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="ban-ben-ji-lian-jie"&gt;版本及连接&lt;/h2&gt;
&lt;p&gt;elasticseearch版本: 2.3.3&lt;/p&gt;
&lt;p&gt;相关链接:
- &lt;a href="https://www.elastic.co/products/elasticsearch"&gt;官网&lt;/a&gt;
- &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="xi-tong-yao-qiu"&gt;系统要求&lt;/h2&gt;
&lt;p&gt;如果仅作测试用, 不需要两天机器, 可以将两个节点部署在同一台机器上, 对磁盘/cpu要求不高, 内存大于2g基本足够了&lt;/p&gt;
&lt;p&gt;如果是正式环境, 需要根据日志量进行评估, 例如, 每天日志量占硬盘约约10G, 且保留30天日志, 则磁盘会占用约300g, es设定的阈值是磁盘空间占满85%则日志开始告警. 所以, 需要至少 &lt;code&gt;300/0.85=354g&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;准备两台机器, 在同一个局域网内(可ping通), 分别在每台机器上部署相应es节点, 搭建一套日志集群.&lt;/p&gt;
&lt;p&gt;两台机器, 最少的资源了, 但是没法做到高可用, 所以, 还需要再加一台机器, 防止脑裂, 具体见最后(两台主力机器+一台稳定的机器就行)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群节点: 最少两台机器&lt;/li&gt;
&lt;li&gt;内存: 16G及以上&lt;/li&gt;
&lt;li&gt;cpu: 4核及以上&lt;/li&gt;
&lt;li&gt;硬盘: 800G及以上, 建议1T, 集群容量约10亿级(取决于对应日志大小)&lt;/li&gt;
&lt;li&gt;操作系统: centos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里假设, 两台机器ip分别为&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;第一台机器: 10.0.0.1
第二台机器: 10.0.0.2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;机器系统为&lt;code&gt;centos6.5&lt;/code&gt;&lt;/p&gt;
&lt;h2 id="bu-shu"&gt;部署&lt;/h2&gt;
&lt;h4 id="1-que-ren-jdkban-ben-ji-an-zhuang"&gt;1. 确认JDK版本及安装&lt;/h4&gt;
&lt;p&gt;es依赖java的版本最小为1.7&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;java -version
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;如果系统中未安装&lt;code&gt;JDK&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;则命令返回&lt;code&gt;bash: java: command not found&lt;/code&gt;, 需要安装&lt;code&gt;JDK&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果系统中安装了JDK, 需确认版本是否大于&lt;code&gt;java 1.7&lt;/code&gt;, 否则需要升级
  &lt;code&gt;java version "1.7.0_51"
  Java(TM) SE Runtime Environment (build 1.7.0_51-b13)
  Java HotSpot(TM) Server VM (build 24.51-b03, mixed mode)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;安装及升级&lt;code&gt;java&lt;/code&gt;(注意根据系统不同运行对应安装命令)&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Redhat/Centos/Fedora&lt;/span&gt;
sudo yum install java-1.7.0-openjdk
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;或者到官网, 下载最新的jdk的rpm包, 然后安装&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wget http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.rpm
rpm -Uvh jdk-8u91-linux-x64.rpm
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再次确认安装成功&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;java -version
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="2-xia-zai-es"&gt;2. 下载es&lt;/h4&gt;
&lt;p&gt;版本: 2.3.3&lt;/p&gt;
&lt;p&gt;下载地址:
- &lt;a href="https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.3.3/elasticsearch-2.3.3.tar.gz"&gt;elasticsearch-2.3.3.tar.gz (tar.gz格式)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;命令行中的下载命令:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -L -O https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.3.3/elasticsearch-2.3.3.tar.gz
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;解压:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tar -xzf elasticsearch-2.3.3.tar.gz
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="3-yong-hu-mu-lu-quan-xian-she-zhi"&gt;3. 用户/目录/权限设置&lt;/h4&gt;
&lt;p&gt;新建用户, 假设为&lt;code&gt;es&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo useradd es
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;新建目录, 假设&lt;code&gt;/data/&lt;/code&gt;目录挂载的硬盘最大(&lt;code&gt;500G&lt;/code&gt;以上)&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkdir -p /data/LogTool
mkdir -p /data/LogData
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将解压后的目录移动至新建的目录&lt;code&gt;/data/LogTool&lt;/code&gt;下, 并改名为&lt;code&gt;elasticsearch&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mv elasticsearch-2.3.3 /data/LogTool/elasticsearch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将目录所有者修改为&lt;code&gt;test&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chown -R es:es /data/LogTool
chown -R es:es /data/LogData
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="5-qie-huan-yong-hu"&gt;5. 切换用户&lt;/h4&gt;
&lt;p&gt;切换到&lt;code&gt;es&lt;/code&gt;用户, 并进入&lt;code&gt;elasticsearch&lt;/code&gt;目录&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;su es
&lt;span class="nb"&gt;cd&lt;/span&gt; /data/LogTool/elasticsearch/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;以用户&lt;code&gt;es&lt;/code&gt;的身份进行后续操作&lt;/p&gt;
&lt;h4 id="6-xiu-gai-pei-zhi-wen-jian"&gt;6. 修改配置文件&lt;/h4&gt;
&lt;p&gt;以用户&lt;code&gt;es&lt;/code&gt;的身份进行操作&lt;/p&gt;
&lt;p&gt;文件路径: &lt;code&gt;config/elasticsearch.yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;修改该文件中配置项: (注意, 原始文件中都是被&lt;code&gt;#&lt;/code&gt;号注释掉了, 需要去掉对应注释并修改配置值)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群名: &lt;code&gt;cluster.name&lt;/code&gt;, 注意: 两台机器配置一致&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cluster.name: inner_es_cluster
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;节点名: &lt;code&gt;node.name&lt;/code&gt;, 注意: 两台机器配置不同, 一台为01, 另一台为02&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 第一台机器
node.name: inner_es_node_01

# 第二台机器
node.name: inner_es_node_02
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;数据路径: &lt;code&gt;path.data&lt;/code&gt;, 为新建立的目录&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path.data: /data/LogData/
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;日志路径: &lt;code&gt;path.logs&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path.logs: /data/LogData/logs
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;LockMemory:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bootstrap.mlockall: true
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;本机ip: &lt;code&gt;network.host&lt;/code&gt;, 注意两台机器配置不同, 分贝配置为对应机器的内网ip&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 第一台机器
network.host: 10.0.0.1

# 第二台机器
network.host: 10.0.0.2
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Discovery配置: 注意这里是两台机器内网ip+9300端口, 注意这里&lt;code&gt;minimum_master_nodes=2&lt;/code&gt;, 见最后一点防脑裂说明&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;discovery.zen.ping.unicast.hosts: ["10.0.0.1:9300", "10.0.0.2:9300"]
discovery.zen.minimum_master_nodes: 2
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;gatewary配置:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gateway.recover_after_nodes: 2
gateway.recover_after_time: 5m
gateway.expected_nodes: 1
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;新增其他配置到文件末尾, 根据需求加, 这里用到了&lt;code&gt;script&lt;/code&gt;, 同时增大了&lt;code&gt;recovery&lt;/code&gt;的配置(要大些保证recovery速度, 但是又不能太大, 会将带宽占满)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script.engine.groovy.inline.search: on
script.engine.groovy.inline.aggs: on
indices.recovery.max_bytes_per_sec: 100mb
indices.recovery.concurrent_streams: 10
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="7-she-zhi-eszhan-yong-nei-cun"&gt;7. 设置es占用内存&lt;/h4&gt;
&lt;p&gt;修改文件&lt;code&gt;bin/elasticsearch.in.sh&lt;/code&gt;, 将文件如下变量变更为&lt;code&gt;4g&lt;/code&gt;(根据自身机器配置, 配置的内存最大不超过机器物理内存的75%. 两个变量值相等, 以获取最大的性能). 当然, 实际使用中&lt;code&gt;4g&lt;/code&gt;可能远远不够, 这个值仅是个示例&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ES_MIN_MEM=4g
ES_MAX_MEM=4g
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改centos配置: &lt;code&gt;/etc/security/limits.conf&lt;/code&gt;, 以便启用memlock, 提升性能&lt;/p&gt;
&lt;p&gt;加入, 注意, 示例中用户为&lt;code&gt;es&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;es soft memlock unlimited
es hard memlock unlimited
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;确认&lt;code&gt;max descriptiors&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;查看系统数量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果结果是&lt;code&gt;unlimited&lt;/code&gt;, 则无需任何处理, 直接进入下一步&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;ulimit&lt;/span&gt; -n
unlimited
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;如果结果是一个整数, 且小于&lt;code&gt;204800&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;ulimit&lt;/span&gt; -n
&lt;span class="m"&gt;4096&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 需要编辑&lt;code&gt;/etc/security/limits.conf&lt;/code&gt;, 加入&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;es soft nofile 204800
es hard nofile 204800
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;另一种方法, 修改&lt;code&gt;bin/elasticsearch&lt;/code&gt;, 在文件的前半部分加入下面这行代码, 保证在启动前执行即可.&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ulimit -n 204800
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="8-qi-dong-ce-shi"&gt;8. 启动测试&lt;/h4&gt;
&lt;p&gt;以用户&lt;code&gt;es&lt;/code&gt;的身份进行操作&lt;/p&gt;
&lt;p&gt;在命令行中执行启动命令&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /data/elasticsearch/
./bin/elasticsearch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以看到程序启动日志&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[2016-06-30 17:20:26,677][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP and CONFIG_SECCOMP_FILTER compiled in
[2016-06-30 17:20:27,390][INFO ][node                     ] [inner_es_node_01] version[2.3.3], pid[6415], build[218bdf1/2016-05-17T15:40:04Z]
[2016-06-30 17:20:27,390][INFO ][node                     ] [inner_es_node_01] initializing ...
[2016-06-30 17:20:27,948][INFO ][plugins                  ] [inner_es_node_01] modules [lang-groovy, reindex, lang-expression], plugins [], sites []
[2016-06-30 17:20:27,974][INFO ][env                      ] [inner_es_node_01] using [1] data paths, mounts [[/data (/dev/xvdb1)]], net usable_space [67.4gb], net total_space [98.4gb], spins? [no], types [ext3]
[2016-06-30 17:20:27,974][INFO ][env                      ] [inner_es_node_01] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-06-30 17:20:29,926][INFO ][node                     ] [inner_es_node_01] initialized
[2016-06-30 17:20:29,926][INFO ][node                     ] [inner_es_node_01] starting ...
[2016-06-30 17:20:30,083][INFO ][transport                ] [inner_es_node_01] publish_address {10.0.0.1:9300}, bound_addresses {10.0.0.1:9300}
[2016-06-30 17:20:30,088][INFO ][discovery                ] [inner_es_node_01] inner_es_cluster/odmTjZRHRVaa8Zn4vTPcxA
[2016-06-30 17:21:00,091][WARN ][discovery                ] [inner_es_node_01] waited for 30s and no initial state was set by the discovery
[2016-06-30 17:21:00,099][INFO ][http                     ] [inner_es_node_01] publish_address {10.0.0.1:9200}, bound_addresses {10.0.0.1:9200}
[2016-06-30 17:21:00,099][INFO ][node                     ] [inner_es_node_01] started
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;等待约一分钟后, 看到如下日志代表启动成功&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[2016-06-30 17:21:00,099][INFO ][node                     ] [inner_es_node_01] started
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;确认集群是否启动成功&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl http://10.0.0.1:9200/

&lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="s2"&gt;"name"&lt;/span&gt; : &lt;span class="s2"&gt;"inner_es_node_01"&lt;/span&gt;,
  &lt;span class="s2"&gt;"cluster_name"&lt;/span&gt; : &lt;span class="s2"&gt;"inner_es_cluster"&lt;/span&gt;,
  &lt;span class="s2"&gt;"version"&lt;/span&gt; : &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;"number"&lt;/span&gt; : &lt;span class="s2"&gt;"2.3.3"&lt;/span&gt;,
    &lt;span class="s2"&gt;"build_hash"&lt;/span&gt; : &lt;span class="s2"&gt;"218bdf10790eef486ff2c41a3df5cfa32dadcfde"&lt;/span&gt;,
    &lt;span class="s2"&gt;"build_timestamp"&lt;/span&gt; : &lt;span class="s2"&gt;"2016-05-17T15:40:04Z"&lt;/span&gt;,
    &lt;span class="s2"&gt;"build_snapshot"&lt;/span&gt; : false,
    &lt;span class="s2"&gt;"lucene_version"&lt;/span&gt; : &lt;span class="s2"&gt;"5.5.0"&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;,
  &lt;span class="s2"&gt;"tagline"&lt;/span&gt; : &lt;span class="s2"&gt;"You Know, for Search"&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动第二个节点时日志&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[2016-06-30 17:32:42,494][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP and CONFIG_SECCOMP_FILTER compiled in
[2016-06-30 17:32:43,295][INFO ][node                     ] [inner_es_node_02] version[2.3.3], pid[10240], build[218bdf1/2016-05-17T15:40:04Z]
[2016-06-30 17:32:43,295][INFO ][node                     ] [inner_es_node_02] initializing ...
[2016-06-30 17:32:43,879][INFO ][plugins                  ] [inner_es_node_02] modules [lang-groovy, reindex, lang-expression], plugins [], sites []
[2016-06-30 17:32:43,905][INFO ][env                      ] [inner_es_node_02] using [1] data paths, mounts [[/data (/dev/xvdb1)]], net usable_space [67.4gb], net total_space [98.4gb], spins? [no], types [ext3]
[2016-06-30 17:32:43,905][INFO ][env                      ] [inner_es_node_02] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-06-30 17:32:45,876][INFO ][node                     ] [inner_es_node_02] initialized
[2016-06-30 17:32:45,876][INFO ][node                     ] [inner_es_node_02] starting ...
[2016-06-30 17:32:45,978][INFO ][transport                ] [inner_es_node_02] publish_address {10.0.0.2:9300}, bound_addresses {10.0.0.2:9300}
[2016-06-30 17:32:45,983][INFO ][discovery                ] [inner_es_node_02] inner_es_cluster/VBsHeFjXQXau59hkjTuhTA
[2016-06-30 17:32:49,067][INFO ][cluster.service          ] [inner_es_node_02] detected_master {inner_es_node_01}{1BktktzhQ_y6BN-lNIKhHg}{10.0.0.1}{10.0.0.1:9300}, added {{inner_es_node_01}{1BktktzhQ_y6BN-lNIKhHg}{10.0.0.1}{10.0.0.1:9300},}, reason: zen-disco-receive(from master [{inner_es_node_01}{1BktktzhQ_y6BN-lNIKhHg}{10.0.0.1}{10.0.0.1:9300}])
[2016-06-30 17:32:49,077][INFO ][http                     ] [inner_es_node_02] publish_address {10.0.0.2:9200}, bound_addresses {10.213.136.23:9201}
[2016-06-30 17:32:49,077][INFO ][node                     ] [inner_es_node_02] started
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意, 日志中&lt;code&gt;cluster.service&lt;/code&gt;部分, 表示发现了第一台机器的节点&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[2016-06-30 17:32:49,067][INFO ][cluster.service          ] [inner_es_node_02] detected_master {inner_es_node_01}{1BktktzhQ_y6BN-lNIKhHg}{10.0.0.1}{10.0.0.1:9300}, added {{inner_es_node_01}{1BktktzhQ_y6BN-lNIKhHg}{10.0.0.1}{10.0.0.1:9300},}, reason: zen-disco-receive(from master [{inner_es_node_01}{1BktktzhQ_y6BN-lNIKhHg}{10.0.0.1}{10.0.0.1:9300}])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动第二个节点后, 同样确认是否启动成功&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl http://10.0.0.1:9200/

&lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="s2"&gt;"name"&lt;/span&gt; : &lt;span class="s2"&gt;"inner_es_node_02"&lt;/span&gt;,
  &lt;span class="s2"&gt;"cluster_name"&lt;/span&gt; : &lt;span class="s2"&gt;"inner_es_cluster"&lt;/span&gt;,
  &lt;span class="s2"&gt;"version"&lt;/span&gt; : &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;"number"&lt;/span&gt; : &lt;span class="s2"&gt;"2.3.3"&lt;/span&gt;,
    &lt;span class="s2"&gt;"build_hash"&lt;/span&gt; : &lt;span class="s2"&gt;"218bdf10790eef486ff2c41a3df5cfa32dadcfde"&lt;/span&gt;,
    &lt;span class="s2"&gt;"build_timestamp"&lt;/span&gt; : &lt;span class="s2"&gt;"2016-05-17T15:40:04Z"&lt;/span&gt;,
    &lt;span class="s2"&gt;"build_snapshot"&lt;/span&gt; : false,
    &lt;span class="s2"&gt;"lucene_version"&lt;/span&gt; : &lt;span class="s2"&gt;"5.5.0"&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;,
  &lt;span class="s2"&gt;"tagline"&lt;/span&gt; : &lt;span class="s2"&gt;"You Know, for Search"&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="9-zheng-shi-qi-dong"&gt;9. 正式启动&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;ctrl+c&lt;/code&gt; 关掉原先的进程&lt;/p&gt;
&lt;p&gt;使用命令, 以daemon形式启动, 进程pid写入&lt;code&gt;es.pid&lt;/code&gt;, 可以用于重启等&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/elasticsearch -d -p es.pid
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$?&lt;/span&gt;
&lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看对应进程是否启动&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ps aux &lt;span class="p"&gt;|&lt;/span&gt; grep elasticsearch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用&lt;code&gt;curl&lt;/code&gt;请求服务确定是否正常&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl http://10.0.0.1:9200/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;或者, 更好的方式, 使用&lt;code&gt;supervisord&lt;/code&gt;管理进程, 以下为&lt;code&gt;supervisord.conf&lt;/code&gt;示例&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[program:es]&lt;/span&gt;
&lt;span class="na"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/LogTool/elasticsearch&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/LogTool/elasticsearch/bin/elasticsearch&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;stdout_logfile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/LogTool/elasticsearch/log/supervisord_es_out.log&lt;/span&gt;
&lt;span class="na"&gt;stderr_logfile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/LogTool/elasticsearch/log/supervisord_es_err.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="10-nao-lie"&gt;10. 脑裂&lt;/h4&gt;
&lt;p&gt;单机测试开发的时候, 其实一个节点就够了. 上线, 使用两个节点, 目的是利用es本身的特性做到高可用.&lt;/p&gt;
&lt;p&gt;但是两个节点是远远不够的. 启动后, 集群会选举一个&lt;code&gt;master&lt;/code&gt;, 一切ok. 但是如果存在网络问题或者某个节点无响应(负载过高), 就会认为对方dead了, 然后两个节点自动选举为&lt;code&gt;master&lt;/code&gt;, 在后续建索引的时候造成数据不一致.&lt;/p&gt;
&lt;p&gt;两个节点防脑裂的配置, &lt;code&gt;minimum_master_nodes&lt;/code&gt;决定了选主需要的最少节点数, &lt;code&gt;N/2+1&lt;/code&gt;, 两个节点即&lt;code&gt;2&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;discovery.zen.minimum_master_nodes: 2 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;但是, 此时一个节点挂了, 则整个集群挂了(无法选举主节点了)&lt;/p&gt;
&lt;p&gt;所以, 要再加一个节点, 这个节点只要保证稳定即可, 对cpu和磁盘要求不高. 这个&lt;code&gt;es&lt;/code&gt;节点的配置同其他节点的区别&lt;code&gt;node.data: false&lt;/code&gt;, 不存储索引数据.&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# split brain prevent
node.data: false
&lt;/pre&gt;&lt;/div&gt;</content><category term="system"></category></entry><entry><title>Logstash+ElasticSearch处理mysql慢查询日志</title><link href="http://www.wklken.me/posts/2016/05/24/elk-mysql-slolog.html" rel="alternate"></link><published>2016-05-24T00:00:00+08:00</published><updated>2016-05-24T00:00:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2016-05-24:/posts/2016/05/24/elk-mysql-slolog.html</id><summary type="html">&lt;p&gt;遇到一个需求, 需要查询某些业务的慢查询日志. 结果DBA平台那边提供的慢查询日志不能解决实际的业务场景(上报的字段补全), 无奈, 自己挽起袖子上&lt;/p&gt;
&lt;p&gt;参考了 &lt;a href="https://www.phase2technology.com/blog/adding-mysql-slow-query-logs-to-logstash/"&gt;这篇文章&lt;/a&gt;, 不过自己根据需求做了较多的变更&lt;/p&gt;
&lt;p&gt;开始吧&lt;/p&gt;
&lt;h2 id="1-zhao-dao-ri-zhi-de-wei-zhi"&gt;1. 找到日志的位置&lt;/h2&gt;
&lt;p&gt;先确认是否开启了, 然后找到日志文件的位置&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; show variables like '%slow%';
+---------------------+-------------------------------------+
| Variable_name       | Value                               |
+---------------------+-------------------------------------+
| log_slow_queries    | ON                                  |
| slow_launch_time    | 2                                   |
| slow_query_log      | ON                                  |
| slow_query_log_file | /data/mysqllog/20000/slow-query.log |
+---------------------+-------------------------------------+
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="2-man-cha-xun-ri-zhi"&gt;2. 慢查询日志&lt;/h2&gt;
&lt;p&gt;格式基本是如下, 当然, 格式如果有差异, 需要根据具体格式进行小的修改&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Time: 160524  5:12:29
# User@Host: user_a[xxxx] @  [10.166.140 …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;遇到一个需求, 需要查询某些业务的慢查询日志. 结果DBA平台那边提供的慢查询日志不能解决实际的业务场景(上报的字段补全), 无奈, 自己挽起袖子上&lt;/p&gt;
&lt;p&gt;参考了 &lt;a href="https://www.phase2technology.com/blog/adding-mysql-slow-query-logs-to-logstash/"&gt;这篇文章&lt;/a&gt;, 不过自己根据需求做了较多的变更&lt;/p&gt;
&lt;p&gt;开始吧&lt;/p&gt;
&lt;h2 id="1-zhao-dao-ri-zhi-de-wei-zhi"&gt;1. 找到日志的位置&lt;/h2&gt;
&lt;p&gt;先确认是否开启了, 然后找到日志文件的位置&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; show variables like '%slow%';
+---------------------+-------------------------------------+
| Variable_name       | Value                               |
+---------------------+-------------------------------------+
| log_slow_queries    | ON                                  |
| slow_launch_time    | 2                                   |
| slow_query_log      | ON                                  |
| slow_query_log_file | /data/mysqllog/20000/slow-query.log |
+---------------------+-------------------------------------+
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="2-man-cha-xun-ri-zhi"&gt;2. 慢查询日志&lt;/h2&gt;
&lt;p&gt;格式基本是如下, 当然, 格式如果有差异, 需要根据具体格式进行小的修改&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Time: 160524  5:12:29
# User@Host: user_a[xxxx] @  [10.166.140.109]
# Query_time: 1.711086  Lock_time: 0.000040 Rows_sent: 385489  Rows_examined: 385489
use dbname;
SET timestamp=1464037949;
SELECT 1 from dbname;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="3-shi-yong-logstash-cai-ji"&gt;3. 使用 logstash 采集&lt;/h2&gt;
&lt;p&gt;采集, 无非是用&lt;code&gt;multiline&lt;/code&gt;进行多行解析&lt;/p&gt;
&lt;p&gt;但是, 需要处理的几个问题&lt;/p&gt;
&lt;p&gt;第一个是, 去除掉没用的信息&lt;/p&gt;
&lt;p&gt;第二个, 慢查询sql, 是会反复出现的, 所以, 执行次数成了一个很重要的指标. 我们要做的, 就是&lt;code&gt;降噪&lt;/code&gt;(将参数去掉, 涉及带引号的内容+数字), 将参数类信息过滤掉, 留下核心的sql, 然后计算出一个hash, 这样就可以在查询, 根据这个字段进行聚合. 这里用到了 &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-add_field"&gt;mutate&lt;/a&gt; 以及 &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-checksum.html"&gt;checksum&lt;/a&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  # calculate unique hash
  mutate {
    add_field =&amp;gt; {"sql_for_hash" =&amp;gt; "%{sql}"}
  }
  mutate {
    gsub =&amp;gt; [
        "sql_for_hash", "'.+?'", "",
        "sql_for_hash", "-?\d*\.{0,1}\d+", ""
    ]
  }
  checksum {
    algorithm =&amp;gt; "md5"
    keys =&amp;gt; ["sql_for_hash"]
  }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最后算出来的md5, 放入了&lt;code&gt;logstash_checksum&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;第三个, 某些sql会非常大, 例如某些不规范的sql可能到几百M或是上G....会直接导致采集进程OOM, 所以, 处理时, 设定超过100k丢弃掉&lt;/p&gt;
&lt;p&gt;第四个, 默认多行处理, 一条sql可能停留在采集端没有上报, 需要等到下一条sql进来, 这样是有问题的, 如果一直没有后续, 最后一条将不会进入引擎. 所以, 在配置中设定了超过5s自动上报&lt;/p&gt;
&lt;p&gt;完整的logstash配置文件(具体使用可能需要根据自身日志格式做些小调整)
注意, 里面的pattern &lt;code&gt;ALLWORD [\s\S]*&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="err"&gt;file&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;path&lt;/span&gt; &lt;span class="err"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"/data/mysqllog/20000/slow-query.log"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
    &lt;span class="err"&gt;sincedb_path&lt;/span&gt; &lt;span class="err"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="err"&gt;"/data/LogNew/logstash/sincedb/mysql.sincedb"&lt;/span&gt;
    &lt;span class="err"&gt;type&lt;/span&gt; &lt;span class="err"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="err"&gt;"mysql-slow-log"&lt;/span&gt;
    &lt;span class="err"&gt;add_field&lt;/span&gt; &lt;span class="err"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"env"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"PRODUCT"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;
    &lt;span class="err"&gt;codec&lt;/span&gt; &lt;span class="err"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="err"&gt;multiline&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
      &lt;span class="err"&gt;pattern&lt;/span&gt; &lt;span class="err"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="err"&gt;"^#&lt;/span&gt; &lt;span class="err"&gt;User@&lt;/span&gt;&lt;span class="n"&gt;Host&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="s2"&gt;      negate =&amp;gt; true&lt;/span&gt;
&lt;span class="s2"&gt;      what =&amp;gt; previous&lt;/span&gt;
&lt;span class="s2"&gt;      max_bytes =&amp;gt; "&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="n"&gt;kib&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="s2"&gt;      auto_flush_interval =&amp;gt; 5&lt;/span&gt;
&lt;span class="s2"&gt;    }&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;filter {&lt;/span&gt;
&lt;span class="s2"&gt;  if ("&lt;/span&gt;&lt;span class="n"&gt;multiline_codec_max_bytes_reached&lt;/span&gt;&lt;span class="s2"&gt;" in &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tags&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;) {&lt;/span&gt;
&lt;span class="s2"&gt;      drop {}&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;  grok {&lt;/span&gt;
&lt;span class="s2"&gt;    # User@Host: logstash&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;logstash&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt; @ localhost &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;127.0.0.1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;    # User@Host: logstash&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;logstash&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt; @  &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;127.0.0.1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;    match =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"^# User@Host: %{ALLWORD:user}\[%{ALLWAORD}\] @ %{ALLWORD:dbhost}? \[%{IP:ip}\]"&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;  grok {&lt;/span&gt;
&lt;span class="s2"&gt;    # Query_time: 102.413328  Lock_time: 0.000167 Rows_sent: 0  Rows_examined: 1970&lt;/span&gt;
&lt;span class="s2"&gt;    match =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"^# Query_time: %{NUMBER:duration:float}%{SPACE}Lock_time: %{NUMBER:lock_wait:float}%{SPACE}Rows_sent: %{NUMBER:results:int}%{SPACE}Rows_examined:%{SPACE}%{NUMBER:scanned:int}%{ALLWORD:sql}"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;

&lt;span class="s2"&gt;  # Capture the time the query happened&lt;/span&gt;
&lt;span class="s2"&gt;  grok {&lt;/span&gt;
&lt;span class="s2"&gt;    match =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"^SET timestamp=%{NUMBER:timestamp};"&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;  # if codec multiline parse failure&lt;/span&gt;
&lt;span class="s2"&gt;  if ("&lt;/span&gt;&lt;span class="n"&gt;_grokparsefailure&lt;/span&gt;&lt;span class="s2"&gt;" in &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tags&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;) {&lt;/span&gt;
&lt;span class="s2"&gt;      drop {}&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;  date {&lt;/span&gt;
&lt;span class="s2"&gt;    match =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"timestamp"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"UNIX"&lt;/span&gt; &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;

&lt;span class="s2"&gt;  mutate {&lt;/span&gt;
&lt;span class="s2"&gt;    gsub =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;SET timestamp=\d+?;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;use [a-zA-Z0-9\-\_]+?;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;# Time: \d+\s+\d+:\d+:\d+"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;/usr/local/mysql/bin/mysqld.+$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Tcp port:.+$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Time .+$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
    &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;



&lt;span class="s2"&gt;  # calculate unique hash&lt;/span&gt;
&lt;span class="s2"&gt;  mutate {&lt;/span&gt;
&lt;span class="s2"&gt;    add_field =&amp;gt; {"&lt;/span&gt;&lt;span class="n"&gt;sql_for_hash&lt;/span&gt;&lt;span class="s2"&gt;" =&amp;gt; "&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"}&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;  mutate {&lt;/span&gt;
&lt;span class="s2"&gt;    gsub =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;
        &lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"'.+?'"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"-?\d*\.{0,1}\d+"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
    &lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;  checksum {&lt;/span&gt;
&lt;span class="s2"&gt;    algorithm =&amp;gt; "&lt;/span&gt;&lt;span class="nt"&gt;md5&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="s2"&gt;    keys =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;

&lt;span class="s2"&gt;  # Drop the captured timestamp field since it has been moved to the time of the event&lt;/span&gt;
&lt;span class="s2"&gt;  mutate {&lt;/span&gt;
&lt;span class="s2"&gt;    # TODO: remove the message field&lt;/span&gt;
&lt;span class="s2"&gt;    remove_field =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"timestamp"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"message"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"sql_for_hash"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;  }&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;
&lt;span class="s2"&gt;output {&lt;/span&gt;
&lt;span class="s2"&gt;    #stdout{&lt;/span&gt;
&lt;span class="s2"&gt;    #    codec =&amp;gt; rubydebug&lt;/span&gt;
&lt;span class="s2"&gt;    #}&lt;/span&gt;
&lt;span class="s2"&gt;    #if ("&lt;/span&gt;&lt;span class="nt"&gt;_grokparsefailure&lt;/span&gt;&lt;span class="s2"&gt;" not in &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tags&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;) {&lt;/span&gt;
&lt;span class="s2"&gt;    #    stdout{&lt;/span&gt;
&lt;span class="s2"&gt;    #        codec =&amp;gt; rubydebug&lt;/span&gt;
&lt;span class="s2"&gt;    #    }&lt;/span&gt;
&lt;span class="s2"&gt;    #}&lt;/span&gt;
&lt;span class="s2"&gt;    if ("&lt;/span&gt;&lt;span class="nt"&gt;_grokparsefailure&lt;/span&gt;&lt;span class="s2"&gt;" not in &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tags&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;) {&lt;/span&gt;
&lt;span class="s2"&gt;        elasticsearch {&lt;/span&gt;
&lt;span class="s2"&gt;          hosts =&amp;gt; &lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"192.168.1.1:9200"&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;          index =&amp;gt; "&lt;/span&gt;&lt;span class="nt"&gt;logstash-slowlog&lt;/span&gt;&lt;span class="err"&gt;"&lt;/span&gt;
        &lt;span class="err"&gt;}&lt;/span&gt;
    &lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;采集进去的内容&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{
           "@timestamp" =&amp;gt; "2016-05-23T21:12:59.000Z",
             "@version" =&amp;gt; "1",
                 "tags" =&amp;gt; [
        [0] "multiline"
    ],
                 "path" =&amp;gt; "/Users/ken/tx/elk/logstash/data/slow_sql.log",
                 "host" =&amp;gt; "Luna-mac-2.local",
                 "type" =&amp;gt; "mysql-slow",
                  "env" =&amp;gt; "PRODUCT",
                 "user" =&amp;gt; "dba_bak_all_sel",
                   "ip" =&amp;gt; "10.166.140.109",
             "duration" =&amp;gt; 28.812601,
            "lock_wait" =&amp;gt; 0.000132,
              "results" =&amp;gt; 749414,
              "scanned" =&amp;gt; 749414,
                  "sql" =&amp;gt; "SELECT /*!40001 SQL_NO_CACHE */ * FROM `xxxxx`;",
    "logstash_checksum" =&amp;gt; "3e3ccb89ee792de882a57e2bef6c5371"
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="4-xie-cha-xun"&gt;4. 写查询&lt;/h2&gt;
&lt;p&gt;查询, 我们需要按&lt;code&gt;logstash_checksum&lt;/code&gt;进行聚合, 然后按照次数由多到少降序展示, 同时, 每个&lt;code&gt;logstash_checksum&lt;/code&gt;需要有一条具体的sql进行展示&lt;/p&gt;
&lt;p&gt;通过 es 的 &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html"&gt;Top hits Aggregation&lt;/a&gt; 可以完美地解决这个查询需求&lt;/p&gt;
&lt;p&gt;查询的query&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;body = {
    "from": 0,
    "size": 0,
    "query": {
        "filtered": {
            "query": {
                "match": {
                    "user": "test"
                }
            },
            "filter": {
                "range": {
                    "@timestamp": {
                        "gte": "now-1d",
                        "lte": "now"
                    }
                }
            }
        }
    },
    "aggs": {
        "top_errors": {
            "terms": {
                "field": "logstash_checksum",
                "size": 20
            },
            "aggs": {
                "top_error_hits": {
                    "top_hits": {
                        "sort": [
                            {
                                "@timestamp":{
                                    "order": "desc"
                                }
                            }
                        ],
                        "_source": {
                            "include": [
                               "user" , "sql", "logstash_checksum", "@timestamp", "duration", "lock_wait", "results", "scanned"
                            ]
                        },
                        "size" : 1
                    }
                }
            }
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;跟这个写法相关的几个参考链接: &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation"&gt;Terms Aggregation&lt;/a&gt; /  &lt;a href="http://stackoverflow.com/questions/25986538/elasticsearch-filter-document-group-by-field"&gt;Elasticsearch filter document group by field&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="5-xuan-ran-ye-mian"&gt;5. 渲染页面&lt;/h2&gt;
&lt;p&gt;python的后台, 使用&lt;code&gt;sqlparse&lt;/code&gt;包, 将sql进行格式化(换行/缩进/大小写), 再往前端传. &lt;a href="https://pypi.python.org/pypi/sqlparse"&gt;sqlparse&lt;/a&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt;&amp;gt;&amp;gt; sql = 'select * from foo where id in (select id from bar);'
&amp;gt;&amp;gt;&amp;gt; print sqlparse.format(sql, reindent=True, keyword_case='upper')
SELECT *
FROM foo
WHERE id IN
  (SELECT id
   FROM bar);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后在页面上, 使用js进行语法高亮  &lt;a href="https://github.com/google/code-prettify"&gt;code-prettify&lt;/a&gt;&lt;/p&gt;</content><category term="system"></category></entry><entry><title>ELK维护的一些点(二)</title><link href="http://www.wklken.me/posts/2016/05/07/elk-about-2.html" rel="alternate"></link><published>2016-05-07T00:00:00+08:00</published><updated>2016-05-07T00:00:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2016-05-07:/posts/2016/05/07/elk-about-2.html</id><summary type="html">&lt;p&gt;很杂, 涉及到最近处理的一些点&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="gen-ju-stringzhuan-fu-dian-shu-de-mou-ge-zi-duan-pai-xu"&gt;根据string转浮点数的某个字段排序&lt;/h3&gt;
&lt;p&gt;一个字段, &lt;code&gt;resp_time&lt;/code&gt;, mapping中是string, 有需求是, 按照响应时间降序排序, 此时需要构造qsl(在search中使用), 使用该字段转换为浮点数, 降序排列&lt;/p&gt;
&lt;p&gt;第一步, 修改es配置, 增加groovy支持&lt;/p&gt;
&lt;p&gt;elasticsearch.yml中加入&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script.engine.groovy.inline.search: on
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, 执行 &lt;a href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html#rolling-restart"&gt;rolling restart&lt;/a&gt;, 逐一重启集群每个节点&lt;/p&gt;
&lt;p&gt;第二步, 构造qsl,  &lt;code&gt;sort&lt;/code&gt;中,  增加&lt;code&gt;_script&lt;/code&gt; 使用groovy脚本, 将对应字段从string转成数字, 再进行排序&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'sort': [{'_script': {'lang': 'groovy',
                       'order': 'desc',
                       'script': 'Float.parseFloat(doc["resp_time"].value)',
                       'type' …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;很杂, 涉及到最近处理的一些点&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="gen-ju-stringzhuan-fu-dian-shu-de-mou-ge-zi-duan-pai-xu"&gt;根据string转浮点数的某个字段排序&lt;/h3&gt;
&lt;p&gt;一个字段, &lt;code&gt;resp_time&lt;/code&gt;, mapping中是string, 有需求是, 按照响应时间降序排序, 此时需要构造qsl(在search中使用), 使用该字段转换为浮点数, 降序排列&lt;/p&gt;
&lt;p&gt;第一步, 修改es配置, 增加groovy支持&lt;/p&gt;
&lt;p&gt;elasticsearch.yml中加入&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script.engine.groovy.inline.search: on
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, 执行 &lt;a href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html#rolling-restart"&gt;rolling restart&lt;/a&gt;, 逐一重启集群每个节点&lt;/p&gt;
&lt;p&gt;第二步, 构造qsl,  &lt;code&gt;sort&lt;/code&gt;中,  增加&lt;code&gt;_script&lt;/code&gt; 使用groovy脚本, 将对应字段从string转成数字, 再进行排序&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'sort': [{'_script': {'lang': 'groovy',
                       'order': 'desc',
                       'script': 'Float.parseFloat(doc["resp_time"].value)',
                       'type': 'number'}},
          {'@timestamp': 'desc'}
          ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;附 &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html"&gt;scripting文档&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="fielddata-format-disableddao-zhi-de-pai-xu-shi-xiao"&gt;&lt;code&gt;fielddata-format-disabled&lt;/code&gt;导致的排序失效&lt;/h3&gt;
&lt;p&gt;有个集群, 升级后, 发现&lt;code&gt;resp_time&lt;/code&gt;字段的mapping是&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;"resp_time" : {
"type" : "string",
"norms" : {
    "enabled" : false
},
"fielddata" : {
    "format" : "disabled"
},
"fields" : {
    "raw" : {
    "type" : "string",
    "index" : "not_analyzed",
    "ignore_above" : 256
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意这里的, 是因为升级es 2.0之后, 默认值变更带来的问题&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;"fielddata" : {
  "format" : "disabled"
},
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html"&gt;fielddata文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;此时, 排序的qsl将会报错, 无法按照对应要求排序&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Field data loading is forbidden on resp_time
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;解决方案, 挺简单的, 使用&lt;code&gt;foo.raw&lt;/code&gt;即可&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'sort': [{'_script': {'lang': 'groovy',
    'order': 'desc',
    'script': 'Float.parseFloat(doc["resp_time.raw"].value)',
    'type': 'number'}},
{'@timestamp': 'desc'}
]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="shi-yong-ju-he"&gt;使用聚合&lt;/h3&gt;
&lt;p&gt;把string类型的&lt;code&gt;resp_time&lt;/code&gt;放到&lt;code&gt;aggs&lt;/code&gt;中做聚合的时候.&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;"aggs": {
     "resp_time_stats": {"stats": {"script": 'Float.parseFloat(doc["resp_time.raw"].value)'}}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 会报错&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{u'error': {u'failed_shards': [{u'index': u'logstash-2016.04.10',
                                u'node': u'AvemqKN-RGKy68zJXUapBg',
                                u'reason': {u'reason': u'scripts of type [inline], operation [aggs] and lang [groovy] are disabled',
                                            u'type': u'script_exception'},
                                u'shard': 0}],
            u'grouped': True,
            u'phase': u'query',
            u'reason': u'all shards failed',
            u'root_cause': [{u'reason': u'scripts of type [inline], operation [aggs] and lang [groovy] are disabled',
                             u'type': u'script_exception'}],
            u'type': u'search_phase_execution_exception'},
 u'status': 500}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理, es加配置, 逐一重启&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script.engine.groovy.inline.aggs: on
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;相关 &lt;a href="https://discuss.elastic.co/t/scripts-of-type-inline-operation-aggs-and-lang-groovy-are-disabled/2493"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="logstash-grok-default-patterns"&gt;logstash grok default patterns&lt;/h3&gt;
&lt;p&gt;默认的一些pattern, 见 &lt;a href="https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns"&gt;grok-patterns&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;grok检查在线实时编辑, https://grokdebug.herokuapp.com/&lt;/p&gt;
&lt;h3 id="logstash-codec-multiline-xian-zhi-xing-shu-he-ri-zhi-da-xiao"&gt;logstash codec multiline 限制行数和日志大小&lt;/h3&gt;
&lt;p&gt;配置, 具体见 &lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-codecs-multiline.html"&gt;multiline文档&lt;/a&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;input {
        codec =&amp;gt; multiline {
            patterns_dir =&amp;gt; "./patterns"
            pattern =&amp;gt; ""
            what =&amp;gt; "previous"
            negate  =&amp;gt; true
            max_lines =&amp;gt; 100
            max_bytes =&amp;gt; "50kib"
        }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;单位 &lt;a href="https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html#bytes"&gt;bytes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;实践中, 使用&lt;code&gt;max_bytes&lt;/code&gt;, 当&lt;code&gt;what=previous + negate=true&lt;/code&gt;的情况下, 即不匹配模式的, 归属前一部分, 这种情况下, 性能ok, 反之&lt;code&gt;what=next + negate=true&lt;/code&gt;的情况下, 不匹配成功归属于后半部分, 此时产生的cpu消耗非常之大, 可以将一台机器跑满.&lt;/p&gt;
&lt;p&gt;另外, 假设配置&lt;code&gt;max_bytes=1M&lt;/code&gt;, 此时用户打了50M, 会给这个event打上tag &lt;code&gt;multiline_codec_max_bytes_reache&lt;/code&gt;, 但是, 这50M 最终还是会经logstash灌入到es里面. 即, 超了, 但是并不自动截掉&lt;/p&gt;
&lt;p&gt;这时候, 我们可以, 使用&lt;code&gt;mutate-replace&lt;/code&gt;直接替换掉&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    # if multiline_codec_max_lines_reached
    if ("multiline_codec_max_bytes_reached" in [tags]) {
        mutate {
            replace =&amp;gt; {
                "message" =&amp;gt; "Log System Warnning: multiline_codec_max_lines_reached, Your log has exceeded 50kB(51200 chars), it was blocked by log system. Please check your code to make your log info shorter and useful"
                "msg" =&amp;gt; "Log System Warnning: multiline_codec_max_lines_reached, Your log has exceeded 50kB(51200 chars), it was blocked by log system. Please check your code to make your log info shorter and useful"
            }
        }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="shi-yong-supervisordguan-li-logstashjin-cheng"&gt;使用supervisord管理logstash进程&lt;/h3&gt;
&lt;p&gt;之前提到, 升级集群后, 使用supervisord统一管理logstash进程, &lt;a href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html#supervisord"&gt;链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="cha-kan-dang-qian-ji-qi-logstashjin-cheng-top"&gt;查看当前机器logstash进程top&lt;/h3&gt;
&lt;p&gt;有时, 需要上机器看看对应采集端所有logstash进程是否存在问题, 常常用到&lt;code&gt;top&lt;/code&gt;命令, 所以写了个简单的脚本, 配合supervisord的脚本使用&lt;/p&gt;
&lt;p&gt;ltop.sh&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
./logstashd.sh status
top -p &lt;span class="k"&gt;$(&lt;/span&gt;./logstashd.sh status &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;'{print $4}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk -F&lt;span class="s1"&gt;','&lt;/span&gt; &lt;span class="s1"&gt;'{print $1}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; tr &lt;span class="s1"&gt;'\n'&lt;/span&gt; &lt;span class="s1"&gt;','&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;'s/,$//g'&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="jin-cheng-zhan-yong-cpujian-ce-jiao-ben"&gt;进程占用cpu检测脚本&lt;/h3&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nv"&gt;BASEDIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;dirname &lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$BASEDIR&lt;/span&gt;
&lt;span class="nv"&gt;CURRENT_DIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; &amp;gt;&amp;gt; /tmp/log/monitor.log &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"=============================================="&lt;/span&gt;
date
&lt;span class="k"&gt;function&lt;/span&gt; check&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nv"&gt;PNAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;
    &lt;span class="nv"&gt;PID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;
    &lt;span class="nv"&gt;CPU_USE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;ps -p &lt;span class="nv"&gt;$PID&lt;/span&gt; -o %cpu &lt;span class="p"&gt;|&lt;/span&gt; sed -n &lt;span class="s1"&gt;'2p'&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;INT_CPU_USE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;printf&lt;/span&gt; &lt;span class="s2"&gt;"%.0f\n"&lt;/span&gt; &lt;span class="nv"&gt;$CPU_USE&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$PNAME&lt;/span&gt;&lt;span class="s2"&gt;" - "&lt;/span&gt;&lt;span class="nv"&gt;$CPU_USE&lt;/span&gt;&lt;span class="s2"&gt;" - "&lt;/span&gt;&lt;span class="nv"&gt;$INT_CPU_USE&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;$INT_CPU_USE&lt;/span&gt; -gt &lt;span class="m"&gt;85&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;then&lt;/span&gt;
       &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$PNAME&lt;/span&gt;&lt;span class="s2"&gt; cpu usage greater than 85%,do restart"&lt;/span&gt;
       ./logstashd.sh restart &lt;span class="nv"&gt;$PNAME&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; -f check
./logstashd.sh status &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;'{print "-", $1, $4}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk -F&lt;span class="s1"&gt;','&lt;/span&gt; &lt;span class="s1"&gt;'{print $1}'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; xargs -n3 bash -c &lt;span class="s1"&gt;'check $@'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="shu-ju-pan-man-liao-dao-zhi-ji-qun-zhuang-tai-yellow"&gt;数据盘满了导致集群状态yellow&lt;/h3&gt;
&lt;p&gt;机器节点本身有1T 硬盘, 由两块盘组成, 配置es的时候, 数据分别写到了两个盘上, 然后有一天集群状态告警了&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;"status" : "yellow",
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看es的日志&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[2016-03-21 12:43:45,934][INFO ][cluster.routing.allocation.decider] [node_01] low disk watermark [85%] exceeded
on [AvemqKN-RGKy68zJXUapBg][node_01][/data/LogNewData/xxx/nodes/0] free: 75.5gb[14.1%], replicas will not be assigned to this node
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理: 腾磁盘空间出来, es会自动检测恢复&lt;/p&gt;
&lt;p&gt;PS: 磁盘大小要预估好&lt;/p&gt;
&lt;h3 id="cha-kan-rediszhong-dui-lie-de-dui-ji"&gt;查看redis中队列的堆积&lt;/h3&gt;
&lt;p&gt;历史遗留问题, 有些节点采集发送到redis的key, 在indexer阶段并没有被消费, 导致越堆越多....&lt;/p&gt;
&lt;p&gt;这时候, 可以通过redis查下哪些队列堆积了&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/redis-cli -h 127.0.0.1 -p 6379 -a blueking_log --bigkeys
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;需要redis版本支持&lt;code&gt;bigkeys&lt;/code&gt; =&amp;gt; This is a "new" feature beginning with 2.8&lt;/p&gt;
&lt;h3 id="jie-xi-shi-bai-diu-qi-ji-hei-ming-dan-shi-xian"&gt;解析失败丢弃及黑名单实现&lt;/h3&gt;
&lt;p&gt;grok解析失败, 丢弃&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if ("_grokparsefailure" in [tags]) {
    drop {}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;有时候, 需要禁止采集某些文件, 但由于&lt;code&gt;file&lt;/code&gt;类型的&lt;code&gt;exclude&lt;/code&gt;只能用文件名, 而没有更强大的规则, 所以只能采集进来再丢弃, 此时, 可以根据路径grok解析出关键字, 然后判断丢弃&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if ([keyworod] in ["data", "not_exists"])
{
    drop {}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="qi-dong-xian-zhi-shi-yong-de-workershu"&gt;启动限制使用的worker数&lt;/h3&gt;
&lt;p&gt;默认情况, 有可能把所有cpu跑满, 这时候, 可以专门加下&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-w, --pipeline-workers COUNT  Sets the number of pipeline workers to run. (default: 24)

logstash agent -f conf/xxx.conf -w 2
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="ji-ge-jian-dan-jiao-ben"&gt;几个简单脚本&lt;/h3&gt;
&lt;p&gt;health.sh&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
curl &lt;span class="s1"&gt;'http://127.0.0.1:9200/_cluster/health?pretty=true'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;indices.sh&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
curl &lt;span class="s1"&gt;'http://127.0.0.1:9200/_cat/indices?v'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort -k &lt;span class="m"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="system"></category></entry><entry><title>ELK 维护的一些点</title><link href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html" rel="alternate"></link><published>2016-02-16T00:00:00+08:00</published><updated>2016-02-16T00:00:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2016-02-16:/posts/2016/02/16/elk-about-upgrade.html</id><summary type="html">&lt;p&gt;去年入职新公司之后, 负责维护平台的elk&lt;/p&gt;
&lt;p&gt;这套东西是2013年搭建的, 年久失修, 所以做了个方案, 开始了批量升级&lt;/p&gt;
&lt;p&gt;将logstash从1.3升级到2.1, 将elasticsearch从1.4.1升级到2.0&lt;/p&gt;
&lt;p&gt;期间踩了很多坑, 搞了一个多月, 总算搞完&lt;/p&gt;
&lt;p&gt;从纯手工落后隔三差五有人找查问题的自行车, 改成自动化最新版本新架构运维便捷上了两个月无人反馈的, 额, 小汽车:) - 集成安装包/shell脚本/fabric实现部署/升级/增删/加黑名单等等功能&lt;/p&gt;
&lt;p&gt;每天日志量大概10G上下, 几十个采集端, 两个redis, 两个indexer, 两台es机器扛起&lt;/p&gt;
&lt;p&gt;以下, 不那么严谨地, 记录一些遇到的问题&lt;/p&gt;
&lt;h4 id="1-logstashsheng-ji-ce-lue"&gt;1. logstash升级策略&lt;/h4&gt;
&lt;p&gt;logstash1.3到2.x, 变化点还是很多的&lt;/p&gt;
&lt;p&gt;所以, 首先第一步要去阅读官方文档, 将所有change log过一遍, 对一些关键性的东西进行了解, 比如, 干掉了哪些语法(旧的功能需要如何实现), 哪些语法有变更, 新增了哪些特性等 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;去年入职新公司之后, 负责维护平台的elk&lt;/p&gt;
&lt;p&gt;这套东西是2013年搭建的, 年久失修, 所以做了个方案, 开始了批量升级&lt;/p&gt;
&lt;p&gt;将logstash从1.3升级到2.1, 将elasticsearch从1.4.1升级到2.0&lt;/p&gt;
&lt;p&gt;期间踩了很多坑, 搞了一个多月, 总算搞完&lt;/p&gt;
&lt;p&gt;从纯手工落后隔三差五有人找查问题的自行车, 改成自动化最新版本新架构运维便捷上了两个月无人反馈的, 额, 小汽车:) - 集成安装包/shell脚本/fabric实现部署/升级/增删/加黑名单等等功能&lt;/p&gt;
&lt;p&gt;每天日志量大概10G上下, 几十个采集端, 两个redis, 两个indexer, 两台es机器扛起&lt;/p&gt;
&lt;p&gt;以下, 不那么严谨地, 记录一些遇到的问题&lt;/p&gt;
&lt;h4 id="1-logstashsheng-ji-ce-lue"&gt;1. logstash升级策略&lt;/h4&gt;
&lt;p&gt;logstash1.3到2.x, 变化点还是很多的&lt;/p&gt;
&lt;p&gt;所以, 首先第一步要去阅读官方文档, 将所有change log过一遍, 对一些关键性的东西进行了解, 比如, 干掉了哪些语法(旧的功能需要如何实现), 哪些语法有变更, 新增了哪些特性等.&lt;/p&gt;
&lt;p&gt;然后, 将线上不同类型agent的配置文件拉下来, 先, 归类, 然后, 开始改-测-改-测-直到测试通过&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/logstash agent -t -f test.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;直到, 语法验证通过&lt;/p&gt;
&lt;p&gt;现在要做的是, 验证数据正确性&lt;/p&gt;
&lt;p&gt;从线上拉取对应日志, 启动, 查看输出&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output {
    stdout{
        debug =&amp;gt; true
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里需要验证的是, 1. 过滤, 该过滤的过滤了 2. 转换, 该转换的转换了 3.新增, 新增字段&lt;/p&gt;
&lt;p&gt;注意, 测试时, 使用逻辑分支覆盖到所有配置文件中的分支即可.&lt;/p&gt;
&lt;p&gt;然后, 可以挑一台机器, 停老的服务, 部署新的服务进行测试&lt;/p&gt;
&lt;p&gt;建议, 部署agent的时候, 如果读的是文件, 建议配置&lt;code&gt;sincedb_path&lt;/code&gt; 这样假设下次升级, 就可以从老的服务最后读取的位置开始了&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;input {
    file {
        path =&amp;gt; ["/data/logs/*.log"]
        sincedb_path =&amp;gt; "/data/LogNew/logstash/sincedb/celery.sincedb"
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="2-elasticsearchsheng-ji-de-ce-lue"&gt;2. elasticsearch升级的策略&lt;/h4&gt;
&lt;p&gt;elasticsearch从1.4到2.0, 部署上变化不大, 变化最大的是存储doc的schema变了......&lt;/p&gt;
&lt;p&gt;使用原来的语法查询, 发现查不到, 因为字段名以及嵌套层级完全不一样了, 这里, 要修改查询端, 兼容新老版本的格式&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{'from': 0,
 'query': {'filtered': {'filter': {'bool': {'must': [{'bool': {'should': [{'term': {'type': 'app'}},
                                                                          {'term': {'@type': 'app'}}]}},
                                                     {'bool': {'should': [{'term': {'log_level': u'error'}},
                                                                          {'term': {'@fields.log_level': u'error'}}]}},
                                                     {'range': {'@timestamp': {'gt': 'now-5h'}}},
                                                     {'bool': {'should': [{'term': {'log_type': u'celery'}},
                                                                          {'term': {'@fields.log_type': u'celery'}}]}}]}}}},
 'size': 100,
 'sort': [{'@timestamp': 'desc'}]}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;另一个是, 取到数据进行解析的时候, 发现解析逻辑跪了, 没办法, 返回的json也完全变了, 这里, 要修改解析逻辑, 兼容新老版本格式&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for hit in log_hits:
    try:
        source = hit.get('_source')
        if '@fields' in source:
            log = source.get('@fields', {})
        else:
            log = source
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;为了让用户感觉不到集群升级, 首先要做的就是上面两个变更&lt;/p&gt;
&lt;p&gt;然后, 搭建新的集群, 最好找新的机器搭建(我在新的机器搭完才发现妈蛋硬盘才100G, 坑死, 无奈在老集群上搭新的集群, 硬盘1t)&lt;/p&gt;
&lt;p&gt;ready, 所有节点起好维护好, 然后, 改indexer, 将同一份日志灌到两个集群&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output {
    elasticsearch {
        hosts =&amp;gt; ["10.1.1.1:9100", "10.1.1.2:9100"]
    }
    elasticsearch {
        hosts =&amp;gt; ["10.1.1.1:9110", "10.1.1.2:9110"]
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;简单测试下, 没问题就放着甭管了, 等数据攒齐了....&lt;/p&gt;
&lt;p&gt;数据够了, 就, 停indexer, 停老集群, 停新集群, 改新集群端口, 起来....同时去掉indexer只输出到新的集群, 起来......测试, 切换完毕, 收工吧.&lt;/p&gt;
&lt;h4 id="you-hua-dian-ji-cheng-an-zhuang-bao-he-supervisord"&gt;优化点: 集成安装包和supervisord&lt;/h4&gt;
&lt;p&gt;额, logstash和es, 如果要配置节点, 其实还是挺蛋疼的&lt;/p&gt;
&lt;p&gt;要做的, 就是, logstash+不同类型配置文件+运维脚本, 达成一个包&lt;/p&gt;
&lt;p&gt;然后, 如果要部署一台机器, 扔上去一键执行安装, 测试, 启动即可&lt;/p&gt;
&lt;p&gt;例如, 运维脚本 &lt;code&gt;logstashd.sh&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;BASEDIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;dirname &lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$BASEDIR&lt;/span&gt;
&lt;span class="nv"&gt;CURRENT_DIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="k"&gt;function&lt;/span&gt; help_msg&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"===================== usage ====================="&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh  - enter command line"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh status - show all configured process"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh start &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - start program"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh stop &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - stop program"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh restart &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - restart program"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh reread &amp;amp;&amp;amp; ./logstashd.sh update - update config and just update the modified programs"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"./logstashd.sh reload - reload config files and restart all programs(stopeed not included)"&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"================================================="&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"-h"&lt;/span&gt; -o &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"--help"&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    help_msg
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;SUPERVISORCTL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'/data/LogNew/python27/bin/supervisorctl'&lt;/span&gt;

&lt;span class="nv"&gt;CONFIG_FILE_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CURRENT_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/conf/supervisord.conf"&lt;/span&gt;

&lt;span class="nv"&gt;$SUPERVISORCTL&lt;/span&gt; -c &lt;span class="nv"&gt;$CONFIG_FILE_PATH&lt;/span&gt; &lt;span class="nv"&gt;$@&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./logstashd.sh
===================== usage =====================
./logstashd.sh  - enter command line
./logstashd.sh status - show all configured process
./logstashd.sh start  - start program
./logstashd.sh stop  - stop program
./logstashd.sh restart  - restart program
./logstashd.sh reread &amp;amp;&amp;amp; ./logstashd.sh update - update config and just update the modified programs
./logstashd.sh reload - reload config files and restart all programs(stopeed not included)
=================================================

111_indexer                      RUNNING   pid 27058, uptime 1:25:10
indexer                          RUNNING   pid 24731, uptime 1:31:29
supervisor&amp;gt; restart indexer
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里, 我引入了&lt;a href="http://www.stackless.com/binaries/"&gt;stackless python&lt;/a&gt; (独立), 然后装pip/supervisord, 使用supervisord对logstash/es进程进行管理&lt;/p&gt;
&lt;p&gt;使用supervisord管理进程, 有个注意点&lt;/p&gt;
&lt;p&gt;默认supervisord相关的文件在&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/tmp/supervisor*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而线上, 存在tmp被删/清理了情况, 导致要进行进程启停操作才发现,妈蛋找不到&lt;/p&gt;
&lt;p&gt;处理方式 =&amp;gt; 放到集成安装包的run目录下&lt;/p&gt;
&lt;h4 id="zhu-yi-dian-logstashcun-zai-liang-ge-outputshi-bi-xu-yao-bao-zheng-er-zhe-de-ke-yong-xing"&gt;注意点: logstash存在两个output时, 必须要保证二者的可用性&lt;/h4&gt;
&lt;p&gt;logstash indexer, 分别转发数据到两个不同的output&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output {
    elasticsearch {
        hosts =&amp;gt; ["10.1.1.1:8080", "10.1.1.2:8080"]
    }
    redis {
        host =&amp;gt; "10.1.1.3"
        port =&amp;gt; 6379
        password =&amp;gt; "7oEsjqUNoTdgE4"
        data_type =&amp;gt; "list"
        key =&amp;gt; "log_queue"
        db =&amp;gt; 0
        batch =&amp;gt; true
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 若是redis挂了, 则日志也不会刷到es中, 所以, 需要同时保证所有output的可用性&lt;/p&gt;
&lt;p&gt;对于redis, 可以进行进程监控, 发现挂了的话, 告警并同时重启(可以crontab一分钟检查一次)&lt;/p&gt;
&lt;h4 id="you-hua-dian-elkzeng-jia-agent_ipzi-duan"&gt;优化点: ELK增加agent_ip字段&lt;/h4&gt;
&lt;p&gt;需求: 在实际使用中, 有时候需要反向根据查询结果, 获知日志的来源机器&lt;/p&gt;
&lt;p&gt;处理:&lt;/p&gt;
&lt;p&gt;1.先获取ip&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;GetLanIp&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="err"&gt;get&lt;/span&gt; &lt;span class="err"&gt;associated&lt;/span&gt; &lt;span class="err"&gt;LAN&lt;/span&gt; &lt;span class="err"&gt;ip&lt;/span&gt; &lt;span class="err"&gt;address&lt;/span&gt;
     &lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;GetLanIp&lt;/span&gt;
     &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sbin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ifconfig&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;awk&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;
&lt;span class="s1"&gt;         /eth/{&lt;/span&gt;
&lt;span class="s1"&gt;             getline;&lt;/span&gt;
&lt;span class="s1"&gt;             if (/inet addr:(172|10|192)\./) {&lt;/span&gt;
&lt;span class="s1"&gt;                 gsub(".*addr:|  *Bcast.*","");&lt;/span&gt;
&lt;span class="s1"&gt;                 print $0;&lt;/span&gt;
&lt;span class="s1"&gt;                 exit;&lt;/span&gt;
&lt;span class="s1"&gt;             }&lt;/span&gt;
&lt;span class="s1"&gt;         }'&lt;/span&gt;
     &lt;span class="n"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2.放入环境变量&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ETH1_IP=10.1.1.1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3.修改logstash配置&lt;/p&gt;
&lt;p&gt;注意, 这里是logstash2.x的语法&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    environment {
        add_metadata_from_env =&amp;gt; ["agent_ip", "ETH1_IP"]
        add_field =&amp;gt; {"agent_ip" =&amp;gt;  "%{[@metadata][agent_ip]}" }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="wen-ti-elkde-utcwen-ti"&gt;问题: elk的utc问题&lt;/h4&gt;
&lt;p&gt;elasticsearch内部使用的是utc, 存储为long (milliseconds since the epoch)  e.g. timestamp=1420070400000&lt;/p&gt;
&lt;p&gt;可以看下 &lt;a href="https://github.com/chenryn/logstash-best-practice-cn/blob/master/filter/date.md"&gt;es 时间处理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;logstash 接受了这种设定, 往es传数据的时候, 根据UTC, 每天00:00新建一个index&lt;/p&gt;
&lt;p&gt;kibana也接受这种设定, 在查询和展示时根据用户的时区进行处理&lt;/p&gt;
&lt;p&gt;问题描述&lt;/p&gt;
&lt;p&gt;这导致了, 对于东八区, 2015-11-6日, 8点之前, 只有&lt;code&gt;logstash-2015.11.05&lt;/code&gt;这个index, 到8点的时候, 创建新的index &lt;code&gt;logstash-2015.11.06&lt;/code&gt;, 即, 对于我们这个时区的人来说, 一天的数据存在了两个index里面&lt;/p&gt;
&lt;p&gt;同类问题 &lt;a href="https://github.com/elastic/elasticsearch/issues/7375"&gt;Elasticsearch doesn't care about timezone and creates indexes with UTC&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;修正方案1: 修改logstash的数据时间&lt;/p&gt;
&lt;p&gt;logstash团队对于支持localtime的问题, 不予修复 &lt;a href="https://logstash.jira.com/browse/LOGSTASH-973"&gt;讨论&lt;/a&gt;, 但是可以自行去修改logstash的代码&lt;/p&gt;
&lt;p&gt;当然, 可以修改每个logstash indexer的时间, 但是会带来问题 &lt;a href="https://github.com/chenryn/logstash-best-practice-cn/blob/master/filter/date.md#时区问题的解释"&gt;问题&lt;/a&gt;: 1. logstash都要修改&lt;code&gt;getLocalTime&lt;/code&gt; 2.相对时间搜索 3. kibana等相关插件/组件要修正&lt;/p&gt;
&lt;p&gt;运维/升级和后续使用上会有很多地雷&lt;/p&gt;
&lt;p&gt;修正方案2: 不修正&lt;/p&gt;
&lt;p&gt;接受这种设定, 学习kibana, 类似自行确定要搜索的index
对于&lt;code&gt;00:00-08:00&lt;/code&gt;的, 程序处理使用昨天的&lt;code&gt;indexer&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所以, 更好的方式是, 不修正......原来不变的才是最好的&lt;/p&gt;
&lt;h4 id="rolling-restart"&gt;rolling restart&lt;/h4&gt;
&lt;p&gt;当存在配置变更时, 需要重启es集群, 不可能全部重启的, 这样会导致服务不可用....&lt;/p&gt;
&lt;p&gt;所以, 要一个个重启&lt;/p&gt;
&lt;p&gt;先执行&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -XPUT 'http://localhost:9200/_cluster/settings' -d '
{
    "transient" : {
        "cluster.routing.allocation.enable" : "none"
    }
}'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, shutdown, 改配置, start&lt;/p&gt;
&lt;p&gt;then : 一定要记得执行, 否则不会执行recovery.....会一直等着&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -XPUT 'http://localhost:9200/_cluster/settings' -d '
{
    "transient" : {
        "cluster.routing.allocation.enable" : "all"
    }
}'
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="logstashwen-ben-jie-xi-pei-zhi-grokyu-fa"&gt;logstash文本解析配置grok语法&lt;/h4&gt;
&lt;p&gt;一个线上的工具, https://grokdebug.herokuapp.com/&lt;/p&gt;
&lt;p&gt;挺好用的, 但是有时候变更频繁相应有些缓慢&lt;/p&gt;
&lt;p&gt;暂时没有找到命令行工具&lt;/p&gt;
&lt;h4 id="keng-grokyu-fa"&gt;坑: GROK语法&lt;/h4&gt;
&lt;p&gt;上线后发现, 尼玛, 部分应用日志没有被采集&lt;/p&gt;
&lt;p&gt;定位发现, 原来在&lt;code&gt;grok&lt;/code&gt;的解析中使用了&lt;code&gt;WORD&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;而 &lt;code&gt;WORD&lt;/code&gt;: 不支持连字符和下划线&lt;/p&gt;
&lt;p&gt;跪了, 需要自定义&lt;code&gt;LOGFILENAME [a-z\-A-Z0-9_\.]+&lt;/code&gt;放到pattern中&lt;/p&gt;
&lt;p&gt;然后, 搜索的时候, 尼玛, 也搜不到....语法要做处理, 使用&lt;code&gt;raw&lt;/code&gt;, es建索引的时候自动拆掉了导致搜索不到&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{'term': {'app_name.raw': 'nms-t'}}
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="zuo-yi-xie-exclude"&gt;做一些exclude&lt;/h4&gt;
&lt;p&gt;有时候需要做一些exclude, 去除比必要采集和监控的日志(进入采集逻辑纯粹是浪费cpu和内存)&lt;/p&gt;
&lt;p&gt;例如, 目录树, 不要监控celery.log&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logs
├── a
│   ├── a.log
│   ├── b.log
│   └── celery.log
└── b
    ├── c.log
        └── d.log
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;排除部分文件&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;file {
    path =&amp;gt; ["/data/logs/*/*.log"]
    exclude =&amp;gt; ["celery.log", ]
    sincedb_path =&amp;gt; "/data/LogNew/logstash/sincedb/django.sincedb"
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-exclude"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h4 id="yi-xie-xiang-guan-yong-dao-de-ming-ling"&gt;一些相关用到的命令&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;查看plugin版本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;https://www.elastic.co/guide/en/logstash/current/working-with-plugins.html&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bin/plugin list --verbose
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;create empty index&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -XPUT 'http://localhost:9100/logstash-2015.12.15/'
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;查看健康度&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl 'http://localhost:9100/_cluster/health?pretty=true'
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;查看indices&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

curl &lt;span class="s1"&gt;'http://localhost:9100/_cat/indices?v'&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort -k &lt;span class="m"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="shan-chu-30tian-qian-crontabjiao-ben"&gt;删除30天前crontab脚本&lt;/h4&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;now&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;date +%Y%m%d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;
&lt;span class="nv"&gt;days_30_before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;date -d &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="s2"&gt; 31 days ago"&lt;/span&gt; +%Y.%m.%d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$days_30_before&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"http://10.1.1.1:9100/logstash-&lt;/span&gt;&lt;span class="nv"&gt;$days_30_before&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
curl -XDELETE &lt;span class="s2"&gt;"http://10.1.1.1:9100/logstash-&lt;/span&gt;&lt;span class="nv"&gt;$days_30_before&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &amp;gt; /dev/null &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="shang-wei-chu-li"&gt;尚未处理&lt;/h4&gt;
&lt;p&gt;logstash2.1 muline codec, 配置多个数据来源, 存在串的情况, 生产中大数据量有, 小规模没有复现....&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;好了, 先这些, 还有一些窝在某些目录下, 后续整理好了发&lt;/p&gt;
&lt;p&gt;wklken&lt;/p&gt;
&lt;p&gt;2016-02-16&lt;/p&gt;</content><category term="system"></category></entry><entry><title>Logstash+ElasticSearch+Kibana处理nginx访问日志</title><link href="http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html" rel="alternate"></link><published>2015-04-26T00:00:00+08:00</published><updated>2015-04-26T00:00:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2015-04-26:/posts/2015/04/26/elk-for-nginx-log.html</id><summary type="html">&lt;p&gt;&lt;code&gt;ELK&lt;/code&gt;似乎是当前最为流行的日志收集-存储-分析的全套解决方案.&lt;/p&gt;
&lt;p&gt;去年年初, 公司里已经在用, 当时自己还&lt;code&gt;山寨&lt;/code&gt;了一个统计系统(postgresql-echarts, 日志无结构化, json形式存储到postgresql, 构建统一前端配置生成, 调用统一查询接口, &lt;a href="http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html"&gt;具体细节&lt;/a&gt;), 已经过了一年有余.&lt;/p&gt;
&lt;p&gt;一年刚好, 发生了很多事, 那套系统不知现在如何了.&lt;/p&gt;
&lt;p&gt;在新的公司, 一切都得从0到1, 近期开始关注日志/数据上报/统计, 以及后续的数据挖掘等.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;搭建, 测试并上线了一套简单的系统, 初期将所有服务器的nginx日志, 以及搜索日志进行处理.&lt;/p&gt;
&lt;p&gt;&lt;img alt="elk" src="/imgs/system/elk.png"/&gt;&lt;/p&gt;
&lt;p&gt;下面主要介绍对nginx日志进行处理的过程, 不是针对&lt;code&gt;elk&lt;/code&gt;的介绍, 所有涉及ip的地方都改成&lt;code&gt;127.0.0.1&lt;/code&gt;了, 根据自己环境进行修改&lt;/p&gt;
&lt;h3 id="1-nginxri-zhi-logstash-shipper-redis"&gt;1. nginx日志 -&amp;gt; logstash shipper -&amp;gt; redis&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;centos&lt;/code&gt;使用&lt;code&gt;yum&lt;/code&gt;安装&lt;code&gt;nginx&lt;/code&gt;后 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;code&gt;ELK&lt;/code&gt;似乎是当前最为流行的日志收集-存储-分析的全套解决方案.&lt;/p&gt;
&lt;p&gt;去年年初, 公司里已经在用, 当时自己还&lt;code&gt;山寨&lt;/code&gt;了一个统计系统(postgresql-echarts, 日志无结构化, json形式存储到postgresql, 构建统一前端配置生成, 调用统一查询接口, &lt;a href="http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html"&gt;具体细节&lt;/a&gt;), 已经过了一年有余.&lt;/p&gt;
&lt;p&gt;一年刚好, 发生了很多事, 那套系统不知现在如何了.&lt;/p&gt;
&lt;p&gt;在新的公司, 一切都得从0到1, 近期开始关注日志/数据上报/统计, 以及后续的数据挖掘等.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;搭建, 测试并上线了一套简单的系统, 初期将所有服务器的nginx日志, 以及搜索日志进行处理.&lt;/p&gt;
&lt;p&gt;&lt;img alt="elk" src="/imgs/system/elk.png"/&gt;&lt;/p&gt;
&lt;p&gt;下面主要介绍对nginx日志进行处理的过程, 不是针对&lt;code&gt;elk&lt;/code&gt;的介绍, 所有涉及ip的地方都改成&lt;code&gt;127.0.0.1&lt;/code&gt;了, 根据自己环境进行修改&lt;/p&gt;
&lt;h3 id="1-nginxri-zhi-logstash-shipper-redis"&gt;1. nginx日志 -&amp;gt; logstash shipper -&amp;gt; redis&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;centos&lt;/code&gt;使用&lt;code&gt;yum&lt;/code&gt;安装&lt;code&gt;nginx&lt;/code&gt;后, 默认&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;中的日志格式定义为:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;log_format&lt;/span&gt;  &lt;span class="s"&gt;main&lt;/span&gt;  &lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="nv"&gt;$remote_addr&lt;/span&gt; &lt;span class="s"&gt;-&lt;/span&gt; &lt;span class="nv"&gt;$remote_user&lt;/span&gt; &lt;span class="s"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$time_local]&lt;/span&gt; &lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$request"&lt;/span&gt; &lt;span class="s"&gt;'&lt;/span&gt;
                  &lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="nv"&gt;$status&lt;/span&gt; &lt;span class="nv"&gt;$body_bytes_sent&lt;/span&gt; &lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$http_referer"&lt;/span&gt; &lt;span class="s"&gt;'&lt;/span&gt;
                  &lt;span class="s"&gt;'"&lt;/span&gt;&lt;span class="nv"&gt;$http_user_agent"&lt;/span&gt; &lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$http_x_forwarded_for"'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后在具体&lt;code&gt;server&lt;/code&gt;配置中使用&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;access_log /data/logs/nginx/{PROJECT_NAME}_access.log main;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时, 我们需要做的是, 将&lt;code&gt;access log&lt;/code&gt;通过&lt;code&gt;logstash shipper&lt;/code&gt;读取, 转&lt;code&gt;json&lt;/code&gt;, 发送到&lt;code&gt;redis&lt;/code&gt;, 由后续的&lt;code&gt;logstash indexer&lt;/code&gt;进行处理&lt;/p&gt;
&lt;p&gt;步骤&lt;/p&gt;
&lt;p&gt;1.在日志所在机器部署&lt;code&gt;logstash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2.在&lt;code&gt;logstash&lt;/code&gt;安装目录下的&lt;code&gt;patterns&lt;/code&gt;中加入一个文件&lt;code&gt;nginx&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;内容(与上面的&lt;code&gt;log_format&lt;/code&gt;相对应)&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;NGUSERNAME [a-zA-Z\.\@\-\+_%]+
NGUSER %{NGUSERNAME}
NGINXACCESS %{IPORHOST:clientip} - %{NOTSPACE:remote_user} \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NOTSPACE:http_x_forwarded_for}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3.增加一个&lt;code&gt;logstash&lt;/code&gt;配置文件: &lt;code&gt;logstash-project-access-log.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意, input的file, filter的grok, output的redis-key&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    input {
    file {
        path =&amp;gt; [ "/data/logs/nginx/xxxx_access.log" ]
        start_position =&amp;gt; "beginning"
    }
    }

    filter {
    mutate { replace =&amp;gt; { "type" =&amp;gt; "nginx_access" } }
    grok {
        match =&amp;gt; { "message" =&amp;gt; "%{NGINXACCESS}" }
    }
    date {
        match =&amp;gt; [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
    }
    geoip {
        source =&amp;gt; "clientip"
    }
    }


    output {
    redis { host =&amp;gt; "127.0.0.1" data_type =&amp;gt; "list" key =&amp;gt; "logstash:xxxx:access_log" }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4.使用&lt;code&gt;supervisor&lt;/code&gt;启动&lt;code&gt;shipper&lt;/code&gt;.&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    [program:logstash_xxxx_shipper]
    command=/var/shell/logstash/bin/logstash -f /var/shell/logstash/configs/nginx-xxxx-shipper.conf
    numprocs=1
    autostart=true
    autorestart=true
    log_stdout=true
    log_stderr=true
    logfile=/data/logs/logstash/logstash_xxxx_access.log
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="2-redis-logstash-indexer-elasticsearch"&gt;2. redis -&amp;gt; logstash indexer -&amp;gt; elasticsearch&lt;/h3&gt;
&lt;p&gt;注意, input的redis为上一步redis配置, key要对应, output的elasticsearch配置, &lt;code&gt;index&lt;/code&gt;指定了最终es中存储对应的index, 加日期, 方便对日志进行定期删除&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;input {
redis {
    host =&amp;gt; "127.0.0.1"
    port =&amp;gt; "6379"
    key =&amp;gt; "logstash:xxxx:access_log"
    data_type =&amp;gt; "list"
    codec  =&amp;gt; "json"
    type =&amp;gt; "logstash-arthas-access"
    tags =&amp;gt; ["arthas"]
}
}

output {
elasticsearch {
    host =&amp;gt; "127.0.0.1"
    index =&amp;gt; "logstash-arthas-access-%{+YYYY.MM.dd}"
}
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="3-elasticsearch-kibana"&gt;3. elasticsearch -&amp;gt; kibana&lt;/h3&gt;
&lt;p&gt;剩下的其实没什么了, 启动&lt;code&gt;kibana&lt;/code&gt;后, 配置好指向的&lt;code&gt;es&lt;/code&gt;, 就可以在&lt;code&gt;kibana&lt;/code&gt;中查看到实时的日志数据&lt;/p&gt;
&lt;p&gt;demo环境截图&lt;/p&gt;
&lt;p&gt;&lt;img alt="kibana-nginx" src="/imgs/system/kibana-nginx.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kibana&lt;/code&gt;中, 支持各种统计, 着实让人惊艳了一把.&lt;/p&gt;
&lt;p&gt;除了基本的nginx日志, 还需要在各类url入口, 加入平台, 渠道等信息, 这样通过nginx访问日志, 可以统计到更多的信息&lt;/p&gt;
&lt;p&gt;当然, 如果需要一些更为精确/特殊的统计, 需要自行进行数据上报的工作.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="hou-xu_1"&gt;后续&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;更多的类型的日志聚合, 包括各类访问日志, 统计上报日志等, 日志落地成文件, 永久留存, 转入es中, 只留存三个月&lt;/li&gt;
&lt;li&gt;如何对各类数据进行拆分/汇总&lt;/li&gt;
&lt;li&gt;ELK整体部署/运维/扩容等, 包括数据清理&lt;/li&gt;
&lt;li&gt;基于ES日志的业务自定义统计后台(kibana无法满足一些具体业务的统计需求)&lt;/li&gt;
&lt;li&gt;为什么不使用&lt;code&gt;logstash forwarder&lt;/code&gt;, 因为目前日志组成等较为简单, 简单处理 , 后续需要用到时再考虑&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h1 id="qi-ta_1"&gt;其他&lt;/h1&gt;
&lt;h2 id="1-guan-yu-logformathe-dui-ying-grokde-pei-zhi"&gt;1. 关于&lt;code&gt;logformat&lt;/code&gt;和对应&lt;code&gt;grok&lt;/code&gt;的配置&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;grok&lt;/code&gt;是&lt;code&gt;logstash&lt;/code&gt;的一个插件,  &lt;a href="http://logstash.net/docs/1.4.2/filters/grok"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Grok is currently the best way in logstash to parse crappy unstructured log data into something structured and queryable&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以, 我们在处理&lt;code&gt;nginx&lt;/code&gt;日志时, 需要根据具体&lt;code&gt;logformat&lt;/code&gt;定义对应的&lt;code&gt;grok&lt;/code&gt;表达式&lt;/p&gt;
&lt;p&gt;除了上面例子中用的那套,  另一份&lt;/p&gt;
&lt;p&gt;logformat&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  log_format logstash '$http_host '
                      '$remote_addr [$time_local] '
                      '"$request" $status $body_bytes_sent '
                      '"$http_referer" "$http_user_agent" '
                      '$request_time '
                      '$upstream_response_time';
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;patterns/nginx&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;NGUSERNAME [a-zA-Z\.\@\-\+_%]+
NGUSER %{NGUSERNAME}
NGINXACCESS %{IPORHOST:http_host} %{IPORHOST:clientip} \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NUMBER:request_time:float} %{NUMBER:upstream_time:float}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果想自行定义, 可以使用 &lt;a href="https://grokdebug.herokuapp.com/"&gt;grokdebug&lt;/a&gt;, 将要解析的日志和配置的正则放入, 可以查看最终得到的结构化数据&lt;/p&gt;
&lt;h2 id="2-elasticsearchcha-jian"&gt;2. elasticsearch插件&lt;/h2&gt;
&lt;p&gt;初期只安装了一个 &lt;a href="https://github.com/lmenezes/elasticsearch-kopf"&gt;kopf&lt;/a&gt;, web界面查看&lt;/p&gt;
&lt;h2 id="3-supervisor"&gt;3. supervisor&lt;/h2&gt;
&lt;p&gt;建议使用&lt;code&gt;supervisor&lt;/code&gt;对&lt;code&gt;elk&lt;/code&gt;进行管理,(ps. 不要用yum自带的, 版本太旧好多坑, 浪费1小时......使用pip install安装最新版本即可)&lt;/p&gt;
&lt;p&gt;配置示例&lt;code&gt;elk.conf&lt;/code&gt;&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[program:elasticsearch]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/elk/elasticsearch/bin/elasticsearch&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;

&lt;span class="k"&gt;[program:kibana]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/elk/kibana/bin/kibana&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;

&lt;span class="k"&gt;[program:logstash_arthas]&lt;/span&gt;
&lt;span class="na"&gt;command&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/var/shell/elk/logstash/bin/logstash -f /var/shell/elk/logstash/config/xxxx_access.conf&lt;/span&gt;
&lt;span class="na"&gt;numprocs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;
&lt;span class="na"&gt;autostart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;autorestart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;log_stdout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;log_stderr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="na"&gt;logfile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/data/logs/elk/logstash/logstash_arthas_access.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="4-logstashkeng"&gt;4. logstash坑&lt;/h2&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;start_position =&amp;gt; "beginning"
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;logstash, 会记录一份文件读到的位置, 在$HOME/.sincedb_xxxxx 如果要让logstash重新读取文件, 删除之即可, 重启&lt;code&gt;shipper&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;但是你可能发现es中重复记录了, 这是因为, 在&lt;code&gt;output&lt;/code&gt;中, 没有定义存储到es时使用的&lt;code&gt;document_id&lt;/code&gt;, es全部当成新纪录存入, 导致数据重复&lt;/p&gt;</content><category term="system"></category></entry><entry><title>基于 PostgreSQL 的数据统计系统</title><link href="http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html" rel="alternate"></link><published>2014-11-16T20:58:00+08:00</published><updated>2014-11-16T20:58:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2014-11-16:/posts/2014/11/16/unit-statistics-system.html</id><summary type="html">&lt;p&gt;看到标题就知道我要写什么了, 这是之前一个项目的小结吧, 自己对统计的一些认识和看法.&lt;/p&gt;
&lt;p&gt;当时从前到后, 包括技术选型, 花了接近一个月的时间, 也在生产上用了两三个月, 一致在持续维护, 做完图表配置化已然接近完工, 无奈后来离开了, 不过目前应该还在运转&lt;/p&gt;
&lt;p&gt;至于源代码, 暂时不考虑开源, 太渣(其中在看了几天js情况下, 自己撸了1000行js的前端框架, 质量堪忧), 全套用python实现.&lt;/p&gt;
&lt;p&gt;提供一种快速实现运营统计需求的思路.&lt;/p&gt;
&lt;p&gt;(图为百度 echarts 示例)&lt;/p&gt;
&lt;p&gt;&lt;img alt="statistics" src="/imgs/system/statistics.png"/&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="yi-chang-jing"&gt;一. 场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;统计&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所谓统计, 抽象出来就是计数而已(还有各个计数之间的算术运算). 再具体一些, 根据不同维度进行计数.&lt;/p&gt;
&lt;p&gt;而统计后台, 无外乎数据的输入, 处理, 及输出.&lt;/p&gt;
&lt;p&gt;对于实时性, 一般会以天为单位进行统计.&lt;/p&gt;
&lt;p&gt;而在具体业务场景下, 需要计数的数据来源于各个项目和同一个项目的不同机器(分布式部署), 就需要考虑, 如何将日志进行汇聚, 如何更为便捷地进行处理, 存储, 以及展现.&lt;/p&gt;
&lt;p&gt;其中要考虑, 需求是不断在变化的, 如何将成本降到最低?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以往的统计方式:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;分析统计需求 -&amp;gt; 修改项目记录日志内容和格式 …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;看到标题就知道我要写什么了, 这是之前一个项目的小结吧, 自己对统计的一些认识和看法.&lt;/p&gt;
&lt;p&gt;当时从前到后, 包括技术选型, 花了接近一个月的时间, 也在生产上用了两三个月, 一致在持续维护, 做完图表配置化已然接近完工, 无奈后来离开了, 不过目前应该还在运转&lt;/p&gt;
&lt;p&gt;至于源代码, 暂时不考虑开源, 太渣(其中在看了几天js情况下, 自己撸了1000行js的前端框架, 质量堪忧), 全套用python实现.&lt;/p&gt;
&lt;p&gt;提供一种快速实现运营统计需求的思路.&lt;/p&gt;
&lt;p&gt;(图为百度 echarts 示例)&lt;/p&gt;
&lt;p&gt;&lt;img alt="statistics" src="/imgs/system/statistics.png"/&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="yi-chang-jing"&gt;一. 场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;统计&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所谓统计, 抽象出来就是计数而已(还有各个计数之间的算术运算). 再具体一些, 根据不同维度进行计数.&lt;/p&gt;
&lt;p&gt;而统计后台, 无外乎数据的输入, 处理, 及输出.&lt;/p&gt;
&lt;p&gt;对于实时性, 一般会以天为单位进行统计.&lt;/p&gt;
&lt;p&gt;而在具体业务场景下, 需要计数的数据来源于各个项目和同一个项目的不同机器(分布式部署), 就需要考虑, 如何将日志进行汇聚, 如何更为便捷地进行处理, 存储, 以及展现.&lt;/p&gt;
&lt;p&gt;其中要考虑, 需求是不断在变化的, 如何将成本降到最低?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以往的统计方式:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;分析统计需求 -&amp;gt; 修改项目记录日志内容和格式(到磁盘) -&amp;gt; 自行将日志汇总到一台机器(rsync) -&amp;gt; crontab脚本分析日志(要删或备份历史数据) -&amp;gt; 新建db表, 存储统计结果 -&amp;gt; 写管理后台, 查询统计结果(最繁琐) -&amp;gt; 处理分页/图表等
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;虽然每次耗时或许并不会太长(0.5-2d, 视需求大小), 但对于不同项目和需求变更, 这些工作都是纯体力毫无技术含量的枯燥工作, 可以说是无意义的资源浪费.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新的方式&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;分析统计需求 -&amp;gt; 确认日志内容和格式  -&amp;gt; 统计后台配置输入/处理/输出逻辑 -&amp;gt; 查看结果
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;说白了就是, 处理统计需求变成了 &lt;code&gt;写sql&lt;/code&gt; + &lt;code&gt;配置&lt;/code&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="er-chu-li-si-lu"&gt;二. 处理思路&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;大体思路如下(从后往前):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1. 将日志进行汇总
2. 日志格式一致化
3. 将日志导入到一个容器中
4. 便捷地通过容器进行计算(计数)
5. 统计结果进行统一存储
6. 提供统一的查询接口
7. 提供前端框架组件, 可以通过配置调用统一查询接口, 并对数据进行分页及图表化
8. 提供配置入口, 可以配置日志入口, 处理逻辑, 展现逻辑. 即完全地配置化
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;需要统一的地方:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;日志格式
容器存储
报告存储
查询接口
前端组件
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;系统成型后&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;增加/修改统计需求: 只需要在后台配置数据来源(日志), 处理逻辑(一段 sql), 展示逻辑(一段前端 json配置), 就可以实现图标
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;h3 id="san-ju-ti"&gt;三. 具体&lt;/h3&gt;
&lt;h3 id="0-ji-ben-jia-gou"&gt;0. 基本架构&lt;/h3&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;             ----------------------------------------------
            |      日志(UniteStats or ApplicationLogs)     |
             ----------------------------------------------
                              ||
                 ---------------------------
                |        load处理程序        |
                 ---------------------------
                              ||
                ___________________________
               |存储容器--计算容器           |
               |                          |
               |  Container(Postgresql)   |   //json - sql - 聚集函数
               |                          |
               |___________________________
                             ||
            --------------------------------------
           |        [自定义统计脚本-查询逻辑及报告表]  |
            --------------------------------------
                             ||
            ---------------------------------------
           |            统计报告                    |
            ---------------------------------------
                            ||
            ---------------------------------------
           |            统一查询接口                |
            ---------------------------------------
                            ||
             ------------------------------------
            |      [自定义前端-使用统一库-配置生成]   |
             ------------------------------------
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="1-ri-zhi-ge-shi"&gt;1. 日志格式&lt;/h3&gt;
&lt;p&gt;日志, 即文本.&lt;/p&gt;
&lt;p&gt;但是文本存在各种格式, 例如常见的’\t’分隔的列, csv, json, xml等等.&lt;/p&gt;
&lt;p&gt;这里的要求是: 一定要满足自描述, 易读(人), 易处理(生成和解析).&lt;/p&gt;
&lt;p&gt;最终选择了&lt;code&gt;json&lt;/code&gt;. 将原先无结构数据转成半结构化数据.&lt;/p&gt;
&lt;p&gt;原因之一, &lt;code&gt;容器&lt;/code&gt;对半结构化的数据支持已经非常完善了, 例如postgresql, mongodb等, 对于后续计算很重要.&lt;/p&gt;
&lt;p&gt;原因之二, 作为一个统一的平台, 我只在乎数据是一份日志, 但是不在乎, 日志里存了些什么, 每个字段的意义, 这些只有平台的使用者需要知道. 否则带来很大一个问题是, 对于使用者在新增或变更一份日志格式时, 需要明确告诉系统这份日志各个字段是什么(名称和类型), 复杂化了&lt;/p&gt;
&lt;p&gt;到这里, 我们统一了日志的格式, 记录为json, 每条记录一行.&lt;/p&gt;
&lt;h3 id="2-ri-zhi-shou-ji-hui-zong"&gt;2. 日志收集汇总&lt;/h3&gt;
&lt;p&gt;目的: 将日志汇总到同一台机器上, 便于统一处理&lt;/p&gt;
&lt;p&gt;命名规则: &lt;code&gt;$THE_LOG_PATH/{projectName}/{projectName}_{moduleName}_{ip}_{yyMMdd}.log&lt;/code&gt; (示例)&lt;/p&gt;
&lt;p&gt;日志汇总的方案有很多:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scp
rsync
nfs
logstash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最终的处理方案: 数据量小, 同一个机房, 使用NFS将日志汇总到目录, 不同机房, 使用rsync进行汇总. 如果数据量大, 可以考虑使用logstash, 直接将日志经过节点处理实时写到一台机器上(就不要分别记录到各自磁盘了).&lt;/p&gt;
&lt;p&gt;扩展: 使用多台机器, 只要保证最终导入同一个库即可.(同一个项目, 同一天存在一张表, 不同机器的日志导入之)&lt;/p&gt;
&lt;p&gt;到这里, 我们将所有json格式的日志汇集到了一起&lt;/p&gt;
&lt;h3 id="3-dao-ru-rong-qi-chu-li"&gt;3. 导入容器处理&lt;/h3&gt;
&lt;p&gt;目前每个项目的日志格式是,&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{projectName}/{projectName}_{moduleName}_{ip}_{yyMMdd}.log
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们会将同一个项目, 可能来自不同机器的日志导入同一张表&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{projectName}/{projectName}_{moduleName}_*_{yyMMdd}.log
=&amp;gt;
table: projectName_moduleName_yyMMdd
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;处理方式: 批量入库, 并且清理保留日期外的表&lt;/p&gt;
&lt;p&gt;建议使用批量导入的方式, 速度杠杠的. Postgresql请使用copy命令&lt;/p&gt;
&lt;h3 id="4-rong-qi"&gt;4. 容器&lt;/h3&gt;
&lt;p&gt;一个计算容器, 仅此而已&lt;/p&gt;
&lt;p&gt;技术选型时, 考虑过Mysql/Mongdb/Redis/MariaDB/OrientDB/CouchDB/RethinkDB等等, 最终敲定使用postgresql, 无它, 对json的完美支持, 满足业务: 一定的数据量, 足够简单的统计方式, 足够稳定, 简单易运维等&lt;/p&gt;
&lt;p&gt;提下&lt;code&gt;redis&lt;/code&gt;, 当时做了整套的&lt;code&gt;redis&lt;/code&gt;方案(接口文档都明确完了就差写代码了), 但是后来毙掉了. (典型的拿着锤子满世界都是钉子的案例). 思想是: 流式日志处理, 根据业务需求使用redis counter, 主从, 后台从redis直接取counter进行展示. 脑洞很大, 可以搞定实时/非实时情况, 还可以顺带把各类业务中的counter需求给做了, 以及更为灵活的展现方式, 但是学习成本较高, 对每个写统计的人要求较高(素质, 具备正确的统计思维, 否则会悲剧掉). 再加上业务本身要求实时性并不高, 所以废弃.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MySql&lt;/code&gt; 对 &lt;code&gt;json&lt;/code&gt; 的支持, 相对于 postgresql 而言逊色太多了, 对&lt;code&gt;json&lt;/code&gt;格式存在限制(多层复杂嵌套的情况)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Mongodb&lt;/code&gt; 虽然对&lt;code&gt;json&lt;/code&gt;支持不错, 但是对于数据量较大的情况支持并不好, 并且查询以及运维都会带来一定困难, 对于使用者有一定学习成本&lt;/p&gt;
&lt;p&gt;PostGresql作为容器的好处:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1. 支持的数据量
2. 查询简单，支持json, 所有sql查询，group by/order by/嵌套子查询，聚集等
3. 各种聚集、统计函数均可用，搞定基本统计查询无障碍（再复杂的都可以）
4. 运维简单
5. 对于开发而言几乎没有学习成本, 会sql再学习下postgresql的json查询
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;示例:
假设搜索日志:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{‘ip’: ‘127.0.0.1’,
 ‘keyword’: ‘test’,
 ‘result_count’: ‘1’,
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;统计 pv&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;select count(data-&amp;gt;'ip') from search_20141101;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;统计 uv&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;select count(DISTINCT data-&amp;gt;&amp;gt;'ip') from search_20141101;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;无结果数&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;select count(*) from search_20141101 where data-&amp;gt;&amp;gt;'result_count' = '0';
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;搜索热词排行榜&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;select data-&amp;gt;&amp;gt;’keyword’, count(*)
from search_20141101
where data-&amp;gt;&amp;gt;'result_count' != '0'
group by data-&amp;gt;&amp;gt;’keyword’
order by count(*) desc
limit 100;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="5-pi-chu-li"&gt;5. 批处理&lt;/h3&gt;
&lt;p&gt;这里要做的事情, 需要有一个管理后台, 让开发可以配置上传自己的处理脚本, 设定脚本执行时间, 执行参数(处理日期/报告表名), 甚至是执行依赖.&lt;/p&gt;
&lt;p&gt;这里需要形成一个约定&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;报告表名: projectName_statsModuleName
报告表一些字段名(因为统一查询接口需要用到): 日期 date,
其他约定字段
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;每天, 系统会扫描并调度任务, 执行, 处理得到统计结果, 存入报告表.&lt;/p&gt;
&lt;p&gt;到这里, 我们每天的统计结果都存入到了报告表中&lt;/p&gt;
&lt;h3 id="6-shu-chu"&gt;6. 输出&lt;/h3&gt;
&lt;p&gt;报告表, 是以时间为维度的, 每条记录带有日期, 每条记录细化到要统计到的精确维度.(具体表现是一个维度会多一列字段), 原则是, 需求分析时充分考虑当前及后续可能的统计需求(要预见还是蛮容易的), 直接将统计维度最细化.&lt;/p&gt;
&lt;p&gt;当然, 如果无法最细化, 后面存在变更, 可以修改统计脚本, 根据情况对历史数据进行重新统计.&lt;/p&gt;
&lt;h3 id="7-tong-yi-cha-xun-ceng"&gt;7. 统一查询层&lt;/h3&gt;
&lt;p&gt;一层通用的接口, 支持传入表名, 条件, 需要结果字段, 格式等, 可以对系统中各类报告表进行各种形式的查询, 获取统计结果.&lt;/p&gt;
&lt;h3 id="8-qian-duan-kuang-jia-ji-zhan-xian"&gt;8. 前端框架及展现&lt;/h3&gt;
&lt;p&gt;是一整套的js款干啊&lt;/p&gt;
&lt;p&gt;分成几块&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成查询表单: 模块化组件, 通过json配置, 自动生成统计查询的表单, 支持各类维度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;配置示例:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;// 产生条件html
    var condition_configs = {
        title: "频道访问统计摘要",
        conditions: [
                {
                    type: "date_begin_to_end", //开始结束日期选择框
                },
                {
                    type: "select",   //下拉框
                    label: "频道",
                    id: "channel",
                    options: [
                        {
                            text: "所有",
                            value: "",
                        },
                        {
                            text: "快速访问",
                            value: "quickaccess",
                        },

                    ]
                },
                {
                    type: "version", //文档框
                },
        ]
    };
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;就会自动生成表单&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;begin_date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;end_date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;组合查询条件: 表单提交时, 根据json配置, 将表单内容/字段/值/表等, 拼接成统一查询层接口需要的请求串&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;查询后数据处理: 将查询后的结果, 根据json配置, 进行转化和展现, 并图表化.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个配置示例:&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;一般文本
{
    'column': 'date',
    'name': '日期',
    'type': 'text',
},

百分比 $后面跟的是sql查询结果列名
{
    'column': 'uninstall_ratio',
    'name': '卸载率',
    'type': 'ratio',
    'value': '$uninstall_pv/$install_pv'
},

公式计算
{
    'column': 'the_qvod_link_pv',
    'name': '导入链接数',
    'type': 'calculate',
    'value': '$qvod_link_pv + $qvod_start_pv'
},

列值翻译
{
    'column': 'channel',
    'name': '渠道',
    'type': 'text',
    'translation': {
        "all": "all",
        "player": "播放器",
        "zx": "资讯",
        "other": "其他导入",
    }
},
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="9-tu-biao"&gt;9. 图表&lt;/h3&gt;
&lt;p&gt;使用百度 &lt;a href="http://echarts.baidu.com/"&gt;echats&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以根据配置, 将统一查询层的接口返回数据直接灌入echats, 生成表单&lt;/p&gt;
&lt;h3 id="10-guo-cheng-ri-zhi-ji-jian-kong"&gt;10. 过程日志及监控&lt;/h3&gt;
&lt;p&gt;需要一组管理表, 进行任务配置/调度/执行/执行结果, 整个过程中的操作可以配置和查看, 用于监控.&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="si-xiao-jie"&gt;四. 小结&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;It’s Simple, but it works.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;数据情况, 当时大概每天 10G 日志 load 到库(处理前&amp;gt;10G), 每天日志数据大概是五千万条, 具体业务上了大概40个的样子, 每天30分钟左右处理完. 对于开发的改进是, 将原先0.5-2d的工作, 缩减到了1-2小时, 对生产力的提升较为显著.(对于日志数多且单一日志量较小的情况处理尤为便捷)&lt;/p&gt;
&lt;p&gt;适用范围: 对于一般团队应该足够了(流量百万级别), 每个项目每天3-5百万访问量, 日志数据10-20G, 当然, 一直没机会测试上限, 不过只要PostGresql能抗住, 量再大些应该也ok.(可以考虑上elasticsearch)&lt;/p&gt;
&lt;p&gt;以上思路, 仅供借鉴:) 就这样吧&lt;/p&gt;</content><category term="system"></category></entry><entry><title>简单搜索系统组成总结</title><link href="http://www.wklken.me/posts/2014/06/09/search-system.html" rel="alternate"></link><published>2014-06-09T00:00:00+08:00</published><updated>2014-06-09T00:00:00+08:00</updated><author><name>wklken</name></author><id>tag:www.wklken.me,2014-06-09:/posts/2014/06/09/search-system.html</id><summary type="html">&lt;p&gt;最近在进行离职前交接工作了, 对之前做的一些东西也大概进行了下简单总结.&lt;/p&gt;
&lt;p&gt;今天整理了下, 搜索系统组成简要描述, 一些思想, 不涉及太多具体实现.&lt;/p&gt;
&lt;p&gt;这套系统从开始设计到最终完成, 前前后后花了3个月的样子(计算所有时间投入), 也算是做得感觉比较完善的一套系统.&lt;/p&gt;
&lt;p&gt;上线接近一年, 支持快玩游戏搜索业务(快玩盒子/快玩网站/移动端等), 系统每天百万级的搜索(峰值在250w左右, 应用层两台机器负载均衡, 单机核心层, 单机引擎), 很遗憾, 由于业务所限, 一直没有看到这套系统能支持的量上限, 即使在峰值, 核心层qps大概也才50左右, 预计搜索量到千万级应该没什么压力, 当然, 优化的余地还很多.&lt;/p&gt;
&lt;p&gt;外面正在狂风骤雨, 开始吧&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="mu-biao"&gt;目标&lt;/h3&gt;
&lt;p&gt;当系统数据达到一定量时, 搜索就成为了除类目以外的第二大入口.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;更好的搜索结果(指标: 召回率, 转化率, 排序效果)&lt;/li&gt;
&lt;li&gt;更好的用户体验(下拉提示点击率,相关搜索准确率等)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="sou-suo-liu-cheng"&gt;搜索流程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;用户在输入框输入关键词, 此时输入框会下拉提示一些词, 用户可以选择进行搜索&lt;/li&gt;
&lt;li&gt;用户点击, 进行搜索, 前端调用搜索接口&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用层&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;3 …&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;最近在进行离职前交接工作了, 对之前做的一些东西也大概进行了下简单总结.&lt;/p&gt;
&lt;p&gt;今天整理了下, 搜索系统组成简要描述, 一些思想, 不涉及太多具体实现.&lt;/p&gt;
&lt;p&gt;这套系统从开始设计到最终完成, 前前后后花了3个月的样子(计算所有时间投入), 也算是做得感觉比较完善的一套系统.&lt;/p&gt;
&lt;p&gt;上线接近一年, 支持快玩游戏搜索业务(快玩盒子/快玩网站/移动端等), 系统每天百万级的搜索(峰值在250w左右, 应用层两台机器负载均衡, 单机核心层, 单机引擎), 很遗憾, 由于业务所限, 一直没有看到这套系统能支持的量上限, 即使在峰值, 核心层qps大概也才50左右, 预计搜索量到千万级应该没什么压力, 当然, 优化的余地还很多.&lt;/p&gt;
&lt;p&gt;外面正在狂风骤雨, 开始吧&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="mu-biao"&gt;目标&lt;/h3&gt;
&lt;p&gt;当系统数据达到一定量时, 搜索就成为了除类目以外的第二大入口.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;更好的搜索结果(指标: 召回率, 转化率, 排序效果)&lt;/li&gt;
&lt;li&gt;更好的用户体验(下拉提示点击率,相关搜索准确率等)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="sou-suo-liu-cheng"&gt;搜索流程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;用户在输入框输入关键词, 此时输入框会下拉提示一些词, 用户可以选择进行搜索&lt;/li&gt;
&lt;li&gt;用户点击, 进行搜索, 前端调用搜索接口&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用层&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;3.1 请求关键词改写, 获得改写后词
3.2 查询缓存是否存在, 存在直接返回缓存内容. 此时, 会记录搜索日志
3.3 不存在缓存, 调用解析输入, 调用核心层接口
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;核心层, 调用引擎接口, 获取搜索结果, 并整合信息, 返回应用层&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;应用层, 获取结果, 此时根据需要, 可能调用相关搜索和热门词服务, 获取必要信息, 最终进行页面渲染, 记录日志, 返回给客户端&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="xi-tong-jie-gou-tu"&gt;系统结构图&lt;/h3&gt;
&lt;p&gt;实现: java(solr)只需配置 + python(所有服务) + golang(suggestion)&lt;/p&gt;
&lt;p&gt;&lt;img alt="search system" src="/imgs/system/search.png"/&gt;&lt;/p&gt;
&lt;h3 id="xi-tong-zu-cheng-jian-dan-miao-shu"&gt;系统组成(简单描述)&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;对外服务  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;搜索整体系统,对外提供服务包括&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基本搜索服务
用户输入query, 系统返回筛选并且排序后的结果, 在前端进行展现&lt;/li&gt;
&lt;li&gt;下拉提示服务
用户在输入框输入query时, 下拉框根据输入提示搜索关键词, google/baidu的搜索框&lt;/li&gt;
&lt;li&gt;相关搜索服务
在搜索结果页,根据用户所在的系统(客户端/移动端/网站等)以及关键词,提示搜索query相关的搜索&lt;/li&gt;
&lt;li&gt;热门搜索
在某些业务中,或者前端,展示热门搜索关键词&lt;/li&gt;
&lt;li&gt;关键词改写
对用户输入关键词进行改写, 以获取更好的搜索结果, 或者进行关键词纠错, 转换&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;缓存&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;缓存在整个搜索系统中起到很关键的作用, 各个服务都需要使用缓存进行优化&lt;/p&gt;
&lt;p&gt;系统使用memcached/redis分别进行处理. 整个搜索中用得最多的是下拉提示suggestion, 用户输入关键词整个过程中存在变动都会发起一次请求.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;业务(应用层+核心层)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;核心层, 提供单一职责, 灵活且性能足够的接口&lt;/p&gt;
&lt;p&gt;应用层, 根据不同系统的业务需求进行编写, 调用核心层接口获取数据, 整合搜索结果, 并进行展示渲染&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;元信息(数据元信息+排行信息等)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;业务本身的核心数据, 包含元信息, 元信息中只有少部分需要导入引擎, 建立索引 or 存储, 元信息中还可能包含排序相关的信息, 例如评分等&lt;/p&gt;
&lt;p&gt;排行信息, 主要来自后端统计系统&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;引擎&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对元信息, 进行分析并处理, 建立索引, 存储内容&lt;/p&gt;
&lt;p&gt;并提供搜索, 可以决定排序规则&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;日志系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;负责记录各个服务的日志, 用于统计以及其他服务的数据挖掘&lt;/p&gt;
&lt;p&gt;可以记录每次搜索的时间,用户,关键词,改写词,是否有结果,结果信息, 翻页信息等等&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;算法模块&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对记录日志进行分析, 使用算法生成其他服务需要的数据&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;报告系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对日志进行统计, 计算搜索pv/uv, 无结果率, 搜索关键词排行, 下拉提示点击率等等&lt;/p&gt;
&lt;p&gt;用于关键性指标的统计, 方便针对性优化&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;接下去, 分块简要说明下&lt;/p&gt;
&lt;h3 id="sou-suo-fu-wu-shu-ju-ceng"&gt;搜索服务-数据层&lt;/h3&gt;
&lt;p&gt;数据存储跟各自业务有关系, 信息录入渠道主要是运营录入或者抓取导入等, 存储使用&lt;code&gt;mysql/postgresql&lt;/code&gt;等数据库&lt;/p&gt;
&lt;p&gt;rank data 主要是由日志系统统计出一些根据涉及排序相关的数据, 例如用户点击次数, 玩次, 评分等等, 会直接影响到结果排序&lt;/p&gt;
&lt;p&gt;注意, 由于这些数据都会存在变更, 所以, 需要存储update_time, 用于引擎增量建立索引.&lt;/p&gt;
&lt;h3 id="sou-suo-fu-wu-yin-qing"&gt;搜索服务-引擎&lt;/h3&gt;
&lt;p&gt;实现上, 使用的是开源的 &lt;a href="http://lucene.apache.org/solr/"&gt;apache solr&lt;/a&gt;, 版本4.5, 刚才看了下最新版到了4.8了. &lt;/p&gt;
&lt;p&gt;曾经一度想自己去实现, 结果发现复杂化了, 系统设计中, 切忌把实现问题的手段当做问题本身去处理.&lt;/p&gt;
&lt;p&gt;还有很多同类引擎, 可以去对比下.&lt;/p&gt;
&lt;p&gt;选中solr的原因: 简单&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输入, 足够简单的数据提供方式, 通过配置文件定义数据库及sql等信息, 就可以建立元数据到引擎数据的关系, 且有接口可以方便地进行全量/增量更新&lt;/li&gt;
&lt;li&gt;配置简单, 可以配置索引处理方式, 例如中文分词,拼音搜索等, 可以配置不同接口的排序, 可以配置缓存等. ps: 拼音搜索可以使用&lt;code&gt;EdgeNGram&lt;/code&gt;索引处理实现.&lt;/li&gt;
&lt;li&gt;输出, 足够强大的查询接口&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于引擎, 很重要一块是搜索结果排序, &lt;code&gt;solr&lt;/code&gt; 可以很方便地支持自定义排序, 可以依赖于输入数据中的排序字段, 进行公式计算, 得到最终的加权和, 用于决定排序. 这里的公式需要针对业务中影响排序的因素进行分析, 然后不断调整因素的权重, 得到最终的排序效果.&lt;/p&gt;
&lt;p&gt;如果要进行一些其他处理, 可以在应用层或核心层进行额外处理.&lt;/p&gt;
&lt;h3 id="xia-la-ti-shi-fu-wu"&gt;下拉提示服务&lt;/h3&gt;
&lt;p&gt;前后做了两个版本, 一个版本基于&lt;code&gt;分词-统计-cache&lt;/code&gt;实现的, 后面一个版本基于 &lt;code&gt;trie树-cache&lt;/code&gt;实现.&lt;/p&gt;
&lt;p&gt;元信息直接导出, 以游戏为例, 游戏名+图标+类型+玩次等信息&lt;/p&gt;
&lt;p&gt;主要是针对游戏名进行处理:(原词+拼音+拼音首字母)&lt;/p&gt;
&lt;div class="monokai"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;植物大战僵尸 -&amp;gt; [植物大战僵尸, zhiwudazhanjiangshi, zwdzjs]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, 在内存中建立前缀树. 这里使用的是&lt;code&gt;double-arry-trie&lt;/code&gt;实现&lt;/p&gt;
&lt;p&gt;&lt;code&gt;double-array-trie&lt;/code&gt;文章: &lt;a href="http://en.wikipedia.org/wiki/Trie"&gt;What is Trie&lt;/a&gt; | &lt;a href="http://linux.thai.net/~thep/datrie/datrie.html"&gt;An Implementation of Double-Array Trie&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;用户输入query, 没发生一次变化, 发送请求到下拉提示服务, 首先会去命中缓存, 未命中, 进入trie树搜索前缀, 获取此前缀所有后缀, 即获取提示关键词集合, 排序获取权重最高的进行返回(是这个流程, 但实际上没那么简单, 要考虑性能).&lt;/p&gt;
&lt;p&gt;如果不开缓存，实时计算的话，对cpu占用率非常高，每次都要搜索&lt;code&gt;trie&lt;/code&gt;树，所以开启了memcached外部缓存.&lt;/p&gt;
&lt;p&gt;开源了一份, 但并不是线上的实现, 而是优化版本, 但是一直没有机会上到线上看下效果, 有兴趣可以看下 &lt;a href="https://github.com/wklken/suggestion"&gt;suggestion&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="xiang-guan-sou-suo-fu-wu"&gt;相关搜索服务&lt;/h3&gt;
&lt;p&gt;目前做得比较简单, 使用同一个用户的搜索关键词链进行分析, 处理成
&lt;code&gt;[ 搜索关键词-后继搜索关键词]&lt;/code&gt;, 并进行统计, 最终获取统计结果.&lt;/p&gt;
&lt;p&gt;这个服务一直没有进行优化, 导致相关搜索的结果并不好, 存在很多bad case(推荐重复的内容/单字符推荐等).&lt;/p&gt;
&lt;p&gt;可以基于算法进行重构.&lt;/p&gt;
&lt;h3 id="guan-jian-ci-gai-xie"&gt;关键词改写&lt;/h3&gt;
&lt;p&gt;关键词改写, 主要分成两类, 一类是输入关键字错误导致无结果(错别字/缺字/多字等), 另一类是输入关键字是业务上某些名称的别名, 系统内没有, 需要转换.&lt;/p&gt;
&lt;p&gt;通过改写, 可以实现纠错以及转换的目的, 使用户能正确获取结果&lt;/p&gt;
&lt;p&gt;关于纠错, 目前处理方式, 用户搜索关键词链, 处理成 &lt;code&gt;[无结果词 - 有结果词]&lt;/code&gt;, 另外还有用户下拉提示点击 &lt;code&gt;[无结果输入词 - 有结果点击词]&lt;/code&gt;, 然后进行统计, 根据一系列规则进行筛选, 获取改写列表.(目前是基于规则的, 优化空间还很大)&lt;/p&gt;
&lt;p&gt;关于业务上的改写, 需要提供入口, 提供给运营人员针对一些术语进行改写, 例如&lt;code&gt;[gta -&amp;gt; 侠盗猎车手]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个服务比较简单粗暴, 计算完成后直接将键值对刷入缓存, 对外提供服务.&lt;/p&gt;
&lt;p&gt;关键词改写需要进行持续的优化, 定期获取新的日志进行批量处理, 加入列表. 优化余地很大, 可以有效降低无结果率.&lt;/p&gt;
&lt;h3 id="tong-ji"&gt;统计&lt;/h3&gt;
&lt;p&gt;主要对每日的搜索日志进行统计, 得到两部分信息:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;报表数据: 不同平台不同渠道的每日pv/uv, 无结果率, 下拉提示点击率等&lt;/li&gt;
&lt;li&gt;排行数据: 不同纬度下搜索排行, 用于反向作用于搜索引擎排序&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h3 id="yi-xie-keng"&gt;一些坑&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;系统使用的&lt;code&gt;memcached&lt;/code&gt;集群作为缓存, 遇到一些坑, 例如&lt;code&gt;key&lt;/code&gt;最大长度250,   &lt;code&gt;key&lt;/code&gt;不能包含空格和控制字符, 存储数据最大1M. 即, 默认对用户的输入不信任(看日志才知道有多少奇葩的搜索query). 切成redis或许会好一些.&lt;/li&gt;
&lt;li&gt;关于备份. 由于业务初期流量一直不大, 所以除了应用层使用&lt;code&gt;nginx&lt;/code&gt;做负载均衡外, 核心层和&lt;code&gt;solr&lt;/code&gt;都使用单机实例. 带来的问题是, 虽然整体负载不高, 但是没有备份, 出现过一次&lt;code&gt;solr&lt;/code&gt;引擎挂到导致搜索整体失效30分钟的故障, 后面对每个单机服务都进行了服务备份, 失效启用.&lt;/li&gt;
&lt;li&gt;需要对整体系统进行监控, 使用&lt;code&gt;sentry&lt;/code&gt;和&lt;code&gt;statsd&lt;/code&gt;, 可以实时监测到流量变化以及程序错误.&lt;/li&gt;
&lt;li&gt;日志很重要, 要针对自己需要了解的指标以及需要统计分析的字段, 设计尽可能完整的日志记录.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h3 id="yi-xie-gan-xiang"&gt;一些感想&lt;/h3&gt;
&lt;p&gt;需要确认整体目标, 然后建立关键性指标, 实现基础方案, 上线, 并持续地关注数据, 分析日志以及bad case, 然后进行优化, 观察指标变化. 记得系统最初的召回率84%, 后来一步步提升到了92%. 这是一个长期的, 不断优化的过程.&lt;/p&gt;
&lt;p&gt;很多东西, 都需要自己一步步去摸索和尝试.&lt;/p&gt;
&lt;p&gt;当然, 这只是一个小型的搜索系统, 其中每一个模块都可以针对性地扩展和优化, 使用更好的算法, 达到更好的效果.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It's simple, but it works, that's enough:)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;系统总是跟随业务逐渐成长变化的, 很可惜, 业务夭折, 这个系统可能失去了在这里继续进化的可能. &lt;/p&gt;
&lt;p&gt;希望提供一些可供大家借鉴的方法. That's all.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;先这样吧&lt;/p&gt;
&lt;p&gt;wklken&lt;/p&gt;
&lt;p&gt;2014-06-09 于深圳&lt;/p&gt;</content><category term="system"></category></entry></feed>